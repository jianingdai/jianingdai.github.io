<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>GNN_Learing</title>
    <url>/2024/11/25/GNN-Learing/</url>
    <content><![CDATA[<h1 id="文档说明："><a href="#文档说明：" class="headerlink" title="文档说明："></a>文档说明：</h1><p>​	我本身的研究方向就是利用<strong>GNN（图神经网络 Graph neural network）</strong>解决<code>软件运维问题/产业链风险问题</code>的，这篇文章就主要是偏向于技术报告似的学习文章，同时也包含一些相关的实验作为支撑。本文章主要以供应链来为例进行说明GNN在供应链等现实实例上面的具体应用方法。</p>
<h1 id="图神经网络"><a href="#图神经网络" class="headerlink" title="图神经网络"></a>图神经网络</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>​	首先就是图无处不在；现实世界中的物体通常用它们与其他事物的联系来定义。一组物体以及它们之间的联系自然地表示为图。我们在这里先明确一下，本文章所提到所有的图（Graph）不是指的 “图像（image）” 中的图，图表示一组实体（节点）之间的关系（边）。【A graph represents the relations (<em>edges</em>) between a collection of entities (<em>nodes</em>).】一个标准的图包括（V,E,U），其中V代表Vertex（节点），E代表Edge（边），U代表Global attributes（全局属性）。如下图（image）中显示的就是一个典型的图：</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202412151605608.png" alt="image-20241215160506512"></p>
<p>​	图中的信息可以通过顶点（Vertex）嵌入或者边（Edge）嵌入等方式来利用图存储信息。全局（或主节点）嵌入。图分为有向图和无向图。</p>
<p>​	目前的研究方向中除了经典的图数据对象，还有例如图像可以化为图【Images as graphs】、文本作为图【Text as graphs】 等等一些意想不到的更为广泛的应用。</p>
<h2 id="典型问题"><a href="#典型问题" class="headerlink" title="典型问题"></a>典型问题</h2><p>​	我们已经描述了一些图的简单介绍，但我们在这些数据上想执行哪些任务呢？在图上，有三种一般的预测任务类型：图级别、节点级别和边级别。</p>
<ol>
<li>在图级任务中，我们预测整个图的一个属性。</li>
<li>对于节点级任务，我们预测图中每个节点的某些属性。</li>
<li>对于边级任务，我们想要预测图中边的属性或存在性。</li>
</ol>
<p>​	对于上述描述的三个预测级别问题（图级别、节点级别和边级别），我们将展示所有这些问题都可以使用单个模型类别，即 GNN 来解决。但首先，让我们在下一章节【<a href="#GNNInSupplyChain">GNN在供应链中的应用</a>】为每个问题提供具体的例子。</p>
<h2 id="机器学习中使用图面临的挑战"><a href="#机器学习中使用图面临的挑战" class="headerlink" title="机器学习中使用图面临的挑战"></a>机器学习中使用图面临的挑战</h2><p>​	那么，我们如何使用神经网络来解决这些不同的图任务呢？第一步是考虑我们如何表示图以与神经网络兼容。</p>
<p>​	机器学习模型通常以矩形或网格状数组作为输入。因此，如何将它们表示为与深度学习兼容的格式并不直观。图有四种类型的信息，我们可能会想要使用它们来进行预测：节点、边、全局上下文和连通性。前三种相对简单：例如，使用节点，我们可以形成一个节点特征矩阵 $N$ ，通过为每个节点分配一个索引 $i$ 并将特征 $node_i$存储在 $N$ 中。虽然这些矩阵具有可变数量的示例，但它们可以无需任何特殊技术进行处理。</p>
<p>​	然而，表示图的连接性更为复杂。最明显的选择可能是使用邻接矩阵，因为这种表示很容易张量化。然而，这种表示有几个缺点。从示例数据集表中，我们看到图中节点的数量可以达到数百万，每个节点的边数可能高度可变。通常，这会导致非常稀疏的邻接矩阵，这会导致空间效率低下。</p>
<p>​	另一个问题是，存在许多可以编码相同连接的邻接矩阵，并且无法保证这些不同的矩阵在深度神经网络中会产生相同的结果（也就是说，它们不是排列不变的）。</p>
<p>​	一种优雅且内存高效的稀疏矩阵表示方法是作为邻接表。这些描述了节点之间的边连接性，例如在邻接表的第 k 个条目中，边 $e_k$ 之间的连接性用元组（i,j）表示。由于我们预计边的数量远低于邻接矩阵的条目数量 $\left( n_{\text{nodes}}^2 \right)$，我们避免了在图的不连通部分进行计算和存储。</p>
<p>应注意，该图使用每个节点&#x2F;边&#x2F;全局的标量值，但大多数实际张量表示具有每个图属性的向量。我们将处理的节点张量大小为 $\left[ n_{\text{n}odes} \right]$ ，而不是 $[n_{\text{nodes}}, node_{\text{dim}}]$ 大小的节点张量。其他图属性也是如此。</p>
<h2 id="最简单的图神经网络："><a href="#最简单的图神经网络：" class="headerlink" title="最简单的图神经网络："></a>最简单的图神经网络：</h2><p>​	使用向量代替标量，我们现在可以构建一个 GNN 了。我们将从最简单的 GNN 架构开始，其中一个我们为所有图属性（节点、边、全局）学习新的嵌入，但我们还没有使用图的连接性。</p>
<p>​	该 GNN 在每个图的组件上使用一个单独的多层感知器（MLP）；我们称这为 GNN 层。对于每个节点向量，我们应用 MLP 并得到一个学习的节点向量。对于每个边，我们学习一个边的嵌入，并且对于全局上下文向量，我们学习整个图的单一嵌入。</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202412151708305.png" alt="image-20241215170814254"></p>
<blockquote>
<p>一个简单 GNN 的单层。图是输入，每个组件（V,E,U）通过 MLP 更新以生成新的图。每个函数下标表示 GNN 模型第 n 层不同图属性的独立函数。</p>
</blockquote>
<p>​	和其他的神经网络模块或者层的常见情况一样，我们可以将这些图神经网络堆叠在一起。</p>
<p>​	因为图神经网络（GNN）不会更新输入图的连接性，所以我们可以用与输入图相同的邻接表和相同数量的特征向量来描述 GNN 的输出图。但是，输出图具有更新的嵌入，因为 GNN 已经更新了每个节点、边和全局上下文表示。</p>
<p>​	现在我们可以构建一个简单的 GNN 模型，并通过在图的不同部分之间路由信息来进行二元预测。这种池化技术将作为构建更复杂 GNN 模型的基石。如果我们有新的图属性，我们只需定义如何从一个属性传递信息到另一个属性。</p>
<h1 id="GNN在供应链中的应用"><a href="#GNN在供应链中的应用" class="headerlink" title="GNN在供应链中的应用"></a><span id="GNNInSupplyChain">GNN在供应链中的应用<span></h1><h2 id="供应链与GNN"><a href="#供应链与GNN" class="headerlink" title="供应链与GNN"></a>供应链与GNN</h2><p>​	供应链是一个动态的组织网络，这些组织参与各种过程和活动，通过上下游的链接为消费者生产以产品和服务形式的价值，涉及信息、商品和资金在其各个阶段的持续流动。由于供应链由复杂网络中的相互连接实体组成，它涉及复杂的相互依赖和决策过程。此外，现代供应链产生大量数据，实体之间的关系和依赖需要复杂的模型来捕捉。使用计算方法解决供应链问题的潜在好处包括提高协调性、高效物流和有效的供应链解决方案。</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202412161345113.png" alt="image-20241216134516991"></p>
<blockquote>
<p>图1：供应链作为相互连接的公司、产品、分销商和客户的图。</p>
</blockquote>
<p>​	GNN在研究领域用于知识图谱推理和异常检测。它们的优势在于有效地捕捉非欧几里得数据中的依赖关系，使它们适用于涉及连接实体的任务。与供应链相连，GNNs 可以实现对供应链中复杂关系和依赖关系的建模，促进销售预测、生产计划、风险评估和揭示潜在风险等任务。 通过利用图神经网络方法，可以优化供应链运营，增强风险管理，并通过从图数据中提取相关信息和推断多种类型的隐藏关系风险来改善决策过程。</p>
<p>​	生产计划在供应链管理中起着关键作用，通过预测未来产品或服务需求，帮助组织优化库存水平、生产计划和资源配置。需求预测的准确性对公司收入有重大影响，促使人们探索各种深度学习和机器学习模型。虽然传统模型已显示出潜力，但图神经网络（GNNs）在模拟供应链中固有的网络结构方面具有独特优势，例如全球贸易流动或社交网络，如图 1 所示。尽管在供应链中关于 GNNs 的研究有限，但最近的研究已经证明了它们在隐藏链接预测等任务中的实用性，以减轻风险和揭示隐藏的依赖关系。 然而，仍存在几个挑战：缺乏针对 GNN 在供应链应用中的全面概念基础和特定公式，研究人员往往缺乏对 GNN 在此领域可以解决的多样化任务的意识。此外，公开可用数据集和适当基准的稀缺阻碍了对供应链中 GNN 模型进行彻底评估和发展的工作。这些差距强调了详细方法和稳健数据集对于推进 GNN 在供应链优化中的研究和实际应用的重要性。</p>
<p>​	近年来，图神经网络（GNN）的进步提高了需求预测和运营弹性，从而实现了更高效和自适应的供应链管理。图表示学习通过揭示供应链网络中的隐藏依赖关系并建立在之前的 GNN 链接预测研究的基础上，进一步提高了链接预测。这些发展突出了机器学习在优化需求预测和生产计划方面的有效性。显著的贡献包括基于 GNN 的隐藏链接预测以减轻风险以及将 GNN 与知识图谱推理相结合以识别潜在风险和提取见解。</p>
<p>​	图神经网络已被应用于供应商推荐，通过分析网络数据在供应链中断期间建议替代供应商。分层可迁移图神经网络简化了复杂的供应链，并使用基于中心性的知识迁移模块进行风险评估。图神经网络还提高了基于供应链数据的行业分类精度，并在供应链金融的欺诈检测和解释中使用了异构图神经网络，利用多视角信息。</p>
<p>​	图可以分为不同类型，包括同构图，其中所有节点和边都是同一类型，以及异构图，涉及多种类型的节点和边。每种类型都针对特定的应用进行定制，具体取决于所表示的结构和关系。同构图适用于更简单的关系，例如社交网络，其中节点代表人物，边代表友谊。然而，异构图具有多种类型的节点和边，可以捕捉更复杂的交互，如以节点代表员工、部门和项目的商业网络。超图通过允许超边连接超过两个节点来进一步扩展这种复杂性，这对于建模多方交互很有用。为不同类型的图设计的不同类型的 GNN 可以用于供应链应用。</p>
<p>​	图神经网络可以分为三种主要类型：卷积型、注意力型和消息传递型。</p>
<ul>
<li><p>​	在供应链分析中，卷积图神经网络可用于需求预测和库存优化等任务，其中各种实体（例如，供应商和分销商）之间的关系相对均匀。这种方法简单直接且计算效率高，使其适用于大规模图。然而，它往往忽略了不同邻居的重要性差异，可能导致在某些关系中比其他关系更重要的情况下性能不佳。在供应链分析中，卷积图神经网络可用于需求预测和库存优化等任务，其中各种实体（例如，供应商和分销商）之间的关系相对均匀。</p>
</li>
<li><p>​	注意力图神经网络通过引入可学习的自注意力机制，为不同的邻居分配不同的重要性，从而解决了卷积图神经网络（GNNs）的局限性。在这种类型中，交互是隐式的。这种方法允许模型专注于更相关的连接，从而提高预测准确性。缺点是计算成本和复杂性的增加。在供应链分析中，注意力图神经网络（Attentional GNNs）特别适用于异常检测和风险管理，能够优先考虑关键关系的能力可以导致更准确的见解。</p>
</li>
<li><p>消息传递图神经网络采用更灵活的方法，允许在边之间传递任意消息。这相当于在边之间计算任意向量（消息）。这种方法高度表达性，能够捕捉图中复杂的依赖关系。然而，它可能计算密集，并且可能需要大量的训练数据才能实现良好的性能。在供应链分析中，消息传递图神经网络可以应用于生产预测和动态路由，其中建模复杂交互的能力至关重要。</p>
</li>
</ul>
<p>​	另一个有趣且有效的用于供应链分析的 GNN 模型是时序图神经网络（Temporal GNN）。时序 GNN 通过引入时间维度扩展了传统的 GNN，使它们能够模拟动态图，其中关系和特征随时间变化。时序 GNN 的一般方程可以表示为：</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202412161426067.png" alt="image-20241216142645029"></p>
<p>​	$𝐡<em>v^{(t)}$表示节点 v 在时间 t 的隐藏状态， 𝒩⁢(v) 表示 v 的邻居， $𝐀</em>{u⁢v}^{(t)}$ 是时间邻接矩阵， $𝐖^{(t)}$ 和 $𝐁^{(t)}$ 是可学习的权重矩阵， σ 是激活函数。时间图神经网络对于建模动态系统至关重要，在这些系统中，关系和特征随时间演变。在供应链分析中，它们能够预测时间依赖现象，如需求波动、运输延误和库存水平。通过捕捉时间模式，这些模型有助于洞察未来趋势，帮助企业优化运营并预测中断。</p>
<p>​	时空图神经网络，作为时间图神经网络的一个子集，结合了空间和时间信息，使它们在供应链分析中特别强大。这些模型不仅能捕捉实体之间不断变化的关系，还能捕捉它们的时空依赖性。在供应链中，时空图神经网络可以显著提高诸如需求预测、动态路线优化和实时库存管理任务的预测准确性。利用空间和时间动态，这些模型能够实现更明智的决策，从而提高供应链运营的效率和弹性。</p>
<p>​	供应链由众多相互连接的组件组成，包括生产设施、产品和原材料。一个行业中存在各种生产设施，每个设施负责生产不同类型的产品或不同库存单位的产品。每个组件，无论是不同的生产设施还是同一生产设施内的不同产品组，都可以表示为图中的一个节点。此图形模型中的连接（边）表示节点之间的关系。同一组内的产品或在同一设施生产的产品由于共同因素（如生产能力、原材料需求和需求趋势）而共享连接。此外，由于共享资源、生产依赖性或物流联系，生产设施之间也可能相互关联。通过采用基于图的方法，可以系统地分析这些复杂关系。这种图形表示允许整合每个节点的各种数据属性，包括需求、生产能力、销售指标，从而实现对供应链网络的全面分析。</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202412161442294.png" alt="image-20241216144207246"></p>
<blockquote>
<p>图 2：同构图中的供应链问题表述。方框代表各种产品类型，颜色表示不同的组别。它们根据产品组和生产设施紧密排列。不同的关系连接表示共享的原材料需求、产品间的相互依赖以及其他影响。</p>
</blockquote>
<p>​	为了说明概念，考虑一家薯片制造公司。这家公司运营两个生产基地，生产四种类型的薯片：普通薯片、三角形薯片、环形薯片和条状薯片，如图 2 所示，每种薯片用不同的颜色表示。每种薯片都有各种包装尺寸，如 30 克、50 克和 100 克，图中的不同盒子表示。在这个图形模型中，连接表示薯片、设施和生产过程之间的关系。例如，同一组的产品或在同一设施生产的产品由于共同因素（如生产能力、原材料需求和需求趋势）而共享连接。如果某薯片组的日生产能力限制为 500 公斤，增加 500 克包装的生产可能需要减少 30 克包装的产量，这表明了内部组之间的依赖性。此外，如果一台机器一次只能生产一种口味，那么在同一天生产多种口味会因为更换时间而效率低下。 如果一个设施专注于特定类型的芯片，在同一设施内生产不同类型可能会导致效率低下。这些相互依赖关系如图 2 所示，在同一设施内以连接的形式呈现。设施间也存在关系，其中在一个设施中生产特定类型的芯片可能会影响另一个设施的生产能力。产品组之间共享的原料可以创造依赖关系，其中一个组的生产会影响另一个组。</p>
<p>​	通过利用基于图的方法，这些复杂关系可以系统性地进行分析。图神经网络利用这种结构化表示来增强生产预测和规划，为供应链管理挑战提供全面解决方案。将供应链问题表述为图，使得供应链元素之间复杂关系的可视化和分析成为可能。图 3 展示了表示供应链网络的异构图。它包括产品（米色）、工厂（青色）和存储位置（紫色）的节点，以及表示这些实体之间关系的边。实线表示产品和工厂之间的连接，而虚线表示产品和存储位置之间的链接，展示了供应链内部的复杂性和相互依赖性。</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202412161443836.png" alt="image-20241216144356771"></p>
<blockquote>
<p>图 3：使用 SCG 数据集的异构图示例。产品、工厂和存储位置是节点，它们之间的关系是边。</p>
</blockquote>
<h2 id="实验部分："><a href="#实验部分：" class="headerlink" title="实验部分："></a>实验部分：</h2><p>这里采用了SCG数据集：该数据集可在 GitHub 上公开获取，网址为 <a href="https://github.com/CIOL-SUST/SCG">https://github.com/CIOL-SUST/SCG</a> ，遵循 LGPL-2.1 许可证。</p>
<p>数据集中的图。数据集包含同构（见图 4 中的示例）和异构（见图 3 中的示例）格式的图，节点特征包含四个时间数据点。图的构建、实现、特征选择以及不同图属性的使用取决于具体的应用和需求。在本文中，我们简要描述了这些方面。</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202412161457262.png" alt="image-20241216145745216"></p>
<blockquote>
<p>图4（a）在这里，节点是子组产品，工厂是边。颜色表示不同类型的节点和边。</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202412161458631.png" alt="image-20241216145815587"></p>
<blockquote>
<p>图4（b）在这里，节点包括产品和存储位置，边表示它们之间的关系。颜色表示不同类型节点和边的不同。</p>
</blockquote>
<blockquote>
<p>图 4：使用 SCG 数据集的均匀图示例。</p>
</blockquote>
<p>​	<strong>数据集统计信息</strong></p>
<table>
<thead>
<tr>
<th>Edge Classes</th>
<th>Edge Count</th>
</tr>
</thead>
<tbody><tr>
<td>Total Edge Types</td>
<td>62</td>
</tr>
<tr>
<td>Total Unique Edges</td>
<td>684</td>
</tr>
<tr>
<td>Class (Group)</td>
<td>5</td>
</tr>
<tr>
<td>Count (Group)</td>
<td>188</td>
</tr>
<tr>
<td>Class (Sub-group)</td>
<td>19</td>
</tr>
<tr>
<td>Count (Sub-group)</td>
<td>52</td>
</tr>
<tr>
<td>Class (Plant)</td>
<td>25</td>
</tr>
<tr>
<td>Count (Plant)</td>
<td>1647</td>
</tr>
<tr>
<td>Class (Storage)</td>
<td>13</td>
</tr>
<tr>
<td>Count (Storage)</td>
<td>3046</td>
</tr>
</tbody></table>
<p>​	在 SCG 中，节点对应不同的产品，而边代表连接这些产品的各种联系：同一产品组或子组，同一工厂或存储位置。</p>
<p>​	在时间数据中，节点特征包括生产、销售订单、分销商的交付和工厂问题。我们有两种模式的所有时间数据：生产单位数量（例如：500 个单位）和生产总重量（例如：10 公吨）。</p>
<p>时间特征的定义：</p>
<ul>
<li>生产，考虑销售订单、客户需求、车辆装载率和交付紧迫性的产品产出量。这个数量通常以单位或公吨来衡量。例如，在一定时间内可能生产了 500 个单位或 10 公吨的产品。</li>
<li>销售订单表示分销商要求的数量，待财务部门批准。它反映了整体产品需求。例如，销售订单可能表明要求 300 个单位或 6 公吨。</li>
<li>发货给分销商表示与订单相符的派送产品，对公司收入有显著影响。例如，发货数据可能显示已向分销商发送了 450 个单位或 9 公吨。</li>
<li>工厂问题涵盖从制造设施发出的所有产品，其中一部分发往分销商，其余的送往仓储仓库。例如，工厂问题报告可能显示已发出 700 个单位或 14 公吨，其中 500 个单位发往分销商，剩余的 200 个单位送往仓库。</li>
</ul>
<h3 id="异常检测："><a href="#异常检测：" class="headerlink" title="异常检测："></a>异常检测：</h3><p>​	为了异常检测，我们以销售订单作为动态时间节点特征，应用具有均方误差损失的模型来识别时间序列数据中的异常。在特定时间段内，图中数据波动增加被视为异常，并需要与公司沟通。这是一种监督方法；遵循 GDN。在模型中，PCA 是一种统计模型；ANN、AE和 LSTM-VAE是基于深度学习的模型；GANF和 GDN是基于 GNN 的时间异常检测模型。在异构任务中，我们利用销售订单数据作为动态时间节点特征。在特定时间段内，图中显著的数据波动被标记为异常，需要与公司沟通。Ad-EHG和 HRGCN是这里的异构 GNN 模型。</p>
<table>
<thead>
<tr>
<th>Models and Type</th>
<th>Model</th>
<th>(k) Anomaly Det. <sup>Hm</sup></th>
<th></th>
<th>(l) Anomaly Det. <sup>Ht</sup></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td></td>
<td>Precision</td>
<td>Recall</td>
<td>Precision</td>
<td>Recall</td>
</tr>
<tr>
<td>Statistical</td>
<td>PCA</td>
<td>31.33%</td>
<td>27.34%</td>
<td>27.24%</td>
<td>28.43%</td>
</tr>
<tr>
<td>Deep Learning</td>
<td>ANN</td>
<td>55.24%</td>
<td>47.75%</td>
<td>53.43%</td>
<td>49.24%</td>
</tr>
<tr>
<td>Deep Learning</td>
<td>AE</td>
<td>75.78%</td>
<td>71.78%</td>
<td>71.22%</td>
<td>69.32%</td>
</tr>
<tr>
<td>Deep Learning</td>
<td>LSTM-VAE</td>
<td>91.87%</td>
<td>86.58%</td>
<td>89.23%</td>
<td>87.24%</td>
</tr>
<tr>
<td>GNN-based</td>
<td>GANF<sup>Hm</sup>&#x2F;Ad-EHG<sup>Ht</sup></td>
<td>85.45%</td>
<td>76.33%</td>
<td>90.34%</td>
<td>89.13%</td>
</tr>
<tr>
<td>GNN-based</td>
<td>GDN<sup>Hm</sup>&#x2F;HRGCN<sup>Ht</sup></td>
<td>94.15%</td>
<td>87.76%</td>
<td>92.43%</td>
<td>89.34%</td>
</tr>
</tbody></table>
<blockquote>
<p>Hm: Homgeneous Graph modelling ( 同构图建模 )，Ht: Heterogeneous Graph modelling ( 异构图建模 )，Det. &#x3D; Detection 检测</p>
</blockquote>
<p>​	在上表中显示，在实验中，基于图模型的得分始终高于其他模型。实验进行了多次，并取平均值。</p>
<p>​	异常检测涉及识别时间序列中与预期模式不符的偏差。在本任务中，表中显示，在精确度和召回率方面，LSTM-VAE 和 GDN 处于领先地位，突显了它们在定位异常方面的有效性。GANF 模型也表现出强劲的性能，强调了基于 GNN 的方法在异常检测中的潜力。</p>
<p>​	在异构异常检测中，目标是检测动态异构图中与预期模式不符的偏差。表中突出显示，基于 GNN 的 HRGCN和 Ad-EHG实现了更高的精确度和召回率，展示了它们在识别异常和突出基于 GNN 的异常检测方法潜力方面的有效性。</p>
]]></content>
      <categories>
        <category>AI</category>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>GNN</tag>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>Unreal为例的游戏模式学习</title>
    <url>/2024/11/23/Unreal%E4%B8%BA%E4%BE%8B%E7%9A%84%E6%B8%B8%E6%88%8F%E6%A8%A1%E5%BC%8F%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="读前须知"><a href="#读前须知" class="headerlink" title="读前须知"></a>读前须知</h1><p>​	在学习这篇笔记之前需要先搭好Unreal Engine的环境，最好是源码版的可以跟着源码一起学习。如果没有相关的环境可以看一下我的这一篇笔记：<a href="/2024/11/20/UE5%E5%BC%95%E6%93%8E%E6%BA%90%E7%A0%81%E7%89%88%E7%BC%96%E8%AF%91%E5%92%8CWindows%E7%89%88%E6%9C%AC%E6%89%93%E5%8C%85/" title="UE5引擎源码版编译和Windows版本打包">UE5引擎源码版编译和Windows版本打包</a></p>
<p><strong>附：</strong></p>
<p>​	本笔记也作为我本人的课程作业的一种提交方式。可以直接点击：“<a href="#%E4%BD%9C%E4%B8%9A%E9%83%A8%E5%88%86">作业部分</a>”，跳转到对应的章节。</p>
<h1 id="什么是游戏模式："><a href="#什么是游戏模式：" class="headerlink" title="什么是游戏模式："></a>什么是游戏模式：</h1><p>​	游戏模式是游戏世界里面组织数据和运作规则的方式，例如：</p>
<ol>
<li>这些物体的共同点，不同点，怎么抽象？</li>
<li>世间万物以什么规则运行？</li>
<li>数据如何组织、描述？（就是想要变得内容以什么数据结构进行描述和组织？）</li>
</ol>
<p>这些都是游戏模式所要思考设计的内容。</p>
<h1 id="UE的Gameplay框架："><a href="#UE的Gameplay框架：" class="headerlink" title="UE的Gameplay框架："></a>UE的Gameplay框架：</h1><p>​	UE中的Gameplay框架包括核心系统和用于处理通用Gameplay元素的框架，如Actor、摄像机、组件、控制器、游戏规则、游戏模式、玩家输入、Gameplay定时器和用户界面。</p>
<h2 id="UE的万物之源：UObject"><a href="#UE的万物之源：UObject" class="headerlink" title="UE的万物之源：UObject"></a>UE的万物之源：UObject</h2><blockquote>
<p>参考：<a href="https://dev.epicgames.com/documentation/en-us/unreal-engine/API">Unreal Engine C++ API Reference</a></p>
</blockquote>
<table>
<thead>
<tr>
<th align="center"></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td align="center">Module</td>
<td>CoreUObject</td>
</tr>
<tr>
<td align="center">Header</td>
<td>&#x2F;Engine&#x2F;Source&#x2F;Runtime&#x2F;CoreUObject&#x2F;Public&#x2F;UObject&#x2F;Object.h</td>
</tr>
<tr>
<td align="center">Include</td>
<td>#include “UObject&#x2F;Object.h”</td>
</tr>
<tr>
<td align="center">Source</td>
<td>&#x2F;Engine&#x2F;Source&#x2F;Runtime&#x2F;CoreUObject&#x2F;Private&#x2F;UObject&#x2F;UObjectGlobals.cpp</td>
</tr>
</tbody></table>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">UObject</span>  </span><br><span class="line">(  </span><br><span class="line">    <span class="type">const</span> FObjectInitializer &amp; ObjectInitializer  </span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>​	其中的特性有：</p>
<ul>
<li>元数据、反射生成、GC垃圾回收、序列化</li>
<li>通⽤属性和接⼝（Equals、Clone、GetHashCode、ToString、GetName、GetMetaData<br>等等）</li>
<li>每个物体是由原⼦构成的⸺uobject&#x3D;原⼦</li>
</ul>
<h2 id="物体的表达：Actor-ActorComponent"><a href="#物体的表达：Actor-ActorComponent" class="headerlink" title="物体的表达：Actor+ActorComponent"></a>物体的表达：Actor+ActorComponent</h2><p>​	所有可以放入关卡的对象都是 <strong>Actor</strong>，比如摄像机、静态网格体、玩家起始位置。Actor支持三维变换，例如平移、旋转和缩放。你可以通过游戏逻辑代码（C++或蓝图）创建（生成）或销毁Actor。</p>
<p>在C++中，AActor是所有Actor的基类。</p>
<p>注意：Actor不直接保存变换（位置、旋转和缩放）数据；如Actor的根组件存在，则使用它的变换数据。</p>
<p>​	Components是一种特殊类型的对象，Actor可以将其作为子对象附加到自己身上。Components对于共享公共行为非常有用，例如显示可视表示、播放声音等功能。它们还可以表示特定于项目的概念，例如车辆解释输入并改变自身速度和方向的方式。例如，一个包含用户可控制的汽车、飞机和船只的项目可以通过改变车辆Actor使用的组件来实现车辆控制和移动的差异。</p>
<blockquote>
<p>To be precise : <strong>Components</strong> are a special type of <strong>Object</strong> that <strong>Actors</strong> can attach to themselves as sub-objects. Components are useful for sharing common behaviors, such as the ability to display a visual representation, play sounds. They can also represent project-specific concepts, such as the way a vehicle interprets input and changes its own velocity and orientation. For example, a project with user-controllable cars, aircraft, and boats could implement the differences in vehicle control and movement by changing which Component a vehicle Actor uses.</p>
</blockquote>
<ul>
<li>EC架构（Entity-Component Framework）:⼀个实体和多种能⼒组合的设计模式。<ul>
<li>就像是⼀款即插即⽤，有了设备（Actor），插⼊设备（Component）就能⽤。</li>
</ul>
</li>
<li>SceneComponent赋予Actor空间变化信息:FTransform: Location, Rotation, Scale</li>
<li>舞台上的演员（Actor），各⾃⾝怀绝技（Component），为玩家上演⼀场精彩的游戏。</li>
</ul>
<h2 id="世界的表达：UWorld-ULevel"><a href="#世界的表达：UWorld-ULevel" class="headerlink" title="世界的表达：UWorld + ULevel"></a>世界的表达：UWorld + ULevel</h2><ul>
<li><p>平⾏世界:GameWorld、PIEWorld（编辑器世界）、PreviewWorld(预览）</p>
</li>
<li><p>关卡构成主⼲卡PersistentLevel+⼦关卡</p>
</li>
<li><p>关卡加载LevelStreaming流式异步加载</p>
<ol>
<li>WorldPartition(UE5)<ol>
<li>分成了许多layer（像是切割了许多⽔平⾯，位于不同的⽔平⾯上就会加载加载不同的范围）</li>
<li>每个layer会设置不同的加载范围，在范围内的就会加载</li>
</ol>
</li>
<li>WorldComposition</li>
<li>LoadByLogic</li>
</ol>
</li>
<li><p>关卡⼤⼩和加载距离</p>
<ul>
<li>LevelBounds + StreamingDistance分层</li>
<li>有多少个关卡，最⼤的覆盖的那个盒⼦</li>
</ul>
</li>
<li><p>关卡蓝图LevelScriptActor</p>
<ul>
<li>定义关卡规则⸺⽐如进⼊该关卡速度变慢之类的</li>
</ul>
</li>
</ul>
<h2 id="世界之上⸺UGameInstance-UEngine"><a href="#世界之上⸺UGameInstance-UEngine" class="headerlink" title="世界之上⸺UGameInstance + UEngine"></a>世界之上⸺UGameInstance + UEngine</h2><ul>
<li><p>UGameInstance</p>
<ul>
<li>信息存在于整个游戏的⽣命周期，不随着地图的切换和销毁</li>
<li>⾮常适合⾮业务逻辑的全局管理操作，如全局UI、设置、预加载</li>
</ul>
</li>
<li><p>UEngine</p>
<ul>
<li>管理GameInstance</li>
<li>拉起游戏重要流程</li>
<li>Browse、LoadMap、SetClientTrave…</li>
</ul>
</li>
<li><p>UE游戏拉起流程</p>
<ul>
<li>init–&gt;start–&gt;loadMap</li>
<li>loadMap中加载了许多内容，⽐如world、模型、player之类的</li>
</ul>
</li>
</ul>
<h1 id="UE游戏模式中的重要对象"><a href="#UE游戏模式中的重要对象" class="headerlink" title="UE游戏模式中的重要对象"></a>UE游戏模式中的重要对象</h1><h2 id="AActor：游戏中最重要的实体"><a href="#AActor：游戏中最重要的实体" class="headerlink" title="AActor：游戏中最重要的实体"></a>AActor：游戏中最重要的实体</h2><ul>
<li>根组件提供世界变化信息</li>
<li>作为⽹络同步的基础单位</li>
<li>标志所有权的Owner指针<ul>
<li>通过owner层层追溯，发射⼦弹伤害了某个敌⼈，追溯是谁伤害了敌⼈：⼦弹⸺枪⸺⻆⾊</li>
</ul>
</li>
<li>标志本地权限的Role枚举<ul>
<li>权威端，你说了算，服务器</li>
<li>主控端，本机</li>
<li>模拟端，看到的别的玩家的游玩</li>
</ul>
</li>
<li>⽣命周期<ul>
<li>分类</li>
<li>关卡内摆放的静态Actor<ul>
<li>从map⾥资源⾥拜访来的</li>
<li>最终还是会回到initially component⾥</li>
</ul>
</li>
</ul>
</li>
<li>SpawnActor创建的动态Actor<ol>
<li>本地Spawn</li>
<li>⽹络序列化</li>
</ol>
</li>
<li>重要的⽣命周期函数<ul>
<li>BeginPlay</li>
<li>EndPlay</li>
<li>Tick</li>
</ul>
</li>
<li>重要的⽣命周期函数<ul>
<li>BeginPlay◦ </li>
<li>Tick</li>
<li>EndPlay：在某些条件达成之后就误了<ul>
<li>处理结束之后怎么做</li>
</ul>
</li>
<li>GC完成收尾⼯作<ul>
<li>注意有效性的判断<ul>
<li>从level的数组⾥丢出去，⽆⼈认领</li>
<li>最后被GC回收了</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="APawn：例如国际象棋中的小兵"><a href="#APawn：例如国际象棋中的小兵" class="headerlink" title="APawn：例如国际象棋中的小兵"></a>APawn：例如国际象棋中的小兵</h2><blockquote>
<p>The <strong>Pawn</strong> class is the base class of all Actors that can be controlled by players or AI. A Pawn is the physical representation of a player or AI entity within the world. This not only means that the Pawn determines what the player or AI entity looks like visually, but also how it interacts with the world in terms of collisions and other physical interactions. This can be confusing in certain circumstances as some types of games may not have a visible player mesh or avatar within the game. Regardless, the Pawn still represents the physical location, rotation, etc. of a player or entity within the game. A Character is a special type of Pawn that has the ability to walk around.</p>
<p>By default, there is a one-to-one relationship between Controllers and Pawns; meaning, each Controller controls only one Pawn at any given time. Also, Pawns spawned during gameplay are not automatically possessed by a Controller.</p>
</blockquote>
<p>Pawn类是所有可以由玩家或AI控制的Actor的基类。棋子是玩家或AI实体在世界中的物理表示。这不仅意味着Pawn决定了玩家或AI实体在视觉上的样子，而且还决定了它在碰撞和其他物理交互方面如何与世界互动。这在某些情况下可能会令人困惑，因为某些类型的游戏可能在游戏内没有可见的玩家网格或化身。无论如何，棋子仍然代表游戏中玩家或实体的物理位置，旋转等。角色是一种特殊类型的棋子，有能力四处走动。</p>
<p>默认情况下，控制器和兵之间是一对一的关系;这意味着，每个控制器在任何给定时间只能控制一个兵。此外，游戏过程中产生的棋子不会自动被控制器拥有。</p>
<ul>
<li>可操控的</li>
<li>多种多样的形式<ul>
<li>⻋⼦、机甲（载具）</li>
</ul>
</li>
<li>被controller控制</li>
<li>基础的输⼊、移动框架的⽀持<ul>
<li>⽣产者消费者模型框架</li>
</ul>
</li>
<li>常⽤派⽣类<ul>
<li>ADefaultPawn<ul>
<li>简单球形碰撞 USphereComponent</li>
<li>简单外显 UStaticMeshComponent</li>
<li>简单移动组件 UFloatingPawnMovement</li>
<li>基础的键盘、⼿柄映射</li>
</ul>
</li>
</ul>
</li>
<li>ASpectatorPawn<ul>
<li>去掉外显 UStaticMeshComponent，不应该被别⼈看到</li>
<li>移动组件替换成忽略时间缩放的USpectatorPawnMovement<ul>
<li>观战的时候可以把全局暂停</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="ACharacter-人型角色"><a href="#ACharacter-人型角色" class="headerlink" title="ACharacter 人型角色"></a>ACharacter 人型角色</h2><ul>
<li>近似仿真⼈形的胶囊体碰撞盒UCapsuleComponent<ul>
<li>在保证⼀定真实性的同时，节约性能</li>
<li>缺点：⽐如脚已经离地但是仍然没掉下去，因为胶囊体还没离开</li>
</ul>
</li>
<li>⻣骼模型USkeletalMeshComponent<ul>
<li>⽐如射击的时候要知道打到的是头还是脚</li>
<li>动画蓝图赋予⼈物⽣动表现</li>
</ul>
</li>
<li>⼈物移动组件UCharacterMovementComponent<ol>
<li>配合胶囊体完成Walking\Falling\Swimming\Flying等多种仿真移动计算</li>
<li>提供Custom⾃定义移动模式供扩展</li>
<li>⽹络游戏移动同步架构<ol>
<li>主控端预表现</li>
<li>服务器端校验</li>
<li>模拟端预测<ol>
<li>match进⾏⼀个差值，减少位置的突变，移动不是⼀帧⼀帧的</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ul>
<h1 id="AController和APawn的双向奔赴"><a href="#AController和APawn的双向奔赴" class="headerlink" title="AController和APawn的双向奔赴"></a>AController和APawn的双向奔赴</h1><ul>
<li>通过Possess和PossessedBy你就是个有主的Pawn了。</li>
<li>Controller、PlayerState指针赋值</li>
<li>网络游戏中Role的改变</li>
</ul>
<h1 id="AplayerController"><a href="#AplayerController" class="headerlink" title="AplayerController"></a>AplayerController</h1><p>​	<strong>可以理解为提线木偶的操控者</strong></p>
<ul>
<li>UInputComponent</li>
</ul>
<p>​		绑定输入映射</p>
<ul>
<li>APlayerCameraManager</li>
</ul>
<p>​		通过ViewTarget上相机臂作⽤后的UCameraComponent计算相机位置</p>
<ul>
<li>AHUD (heads-up display) 头显</li>
</ul>
<p>​		注意和UI的区别，逐渐被更灵活的UMG取代</p>
<ul>
<li>⽹络连接所有权</li>
</ul>
<p>​		注意仅在主控端及服务器存在PlayerController</p>
<h1 id="AGameMode"><a href="#AGameMode" class="headerlink" title="AGameMode"></a>AGameMode</h1><p><strong>这个是真的游戏模式</strong></p>
<ul>
<li>仅服务器拥有，掌控整体游戏流程</li>
<li>定义游戏模式⽤的基础类型</li>
<li>纯服务器逻辑的操作，如AI</li>
<li>AGameMode和AGameModeBase区别<ul>
<li>AGameModeBase，这是所有GameMode的基类，是经典的AGameMode简化版本。</li>
<li>AGameMode是AGameModeBase的⼦类。AGameMode更适⽤于标准对抗类游戏（如多⼈射击游戏），完善了对局和⽐赛的概念。</li>
</ul>
</li>
</ul>
<h1 id="AGameState-游戏状态"><a href="#AGameState-游戏状态" class="headerlink" title="AGameState 游戏状态"></a>AGameState 游戏状态</h1><ul>
<li>所有端都共享同步的游戏数据</li>
<li>AGameState和AGameStateBase的区别。</li>
<li>类似AGameMode和AGameModeBase的关系。</li>
<li>AGameState是AGameStateBase的⼦类。</li>
<li>AGameMode更适⽤于标准对抗类游戏（如多⼈射击游戏），完善了对局和⽐赛的概念。</li>
</ul>
<h1 id="APlayerState玩家状态"><a href="#APlayerState玩家状态" class="headerlink" title="APlayerState玩家状态"></a>APlayerState玩家状态</h1><ul>
<li>所有端都共享同步的游戏数据</li>
<li>PlayerState、Character、Controller的职责区别</li>
</ul>
<h1 id="作业部分："><a href="#作业部分：" class="headerlink" title="作业部分："></a><span id = "作业部分">作业部分：<span></h1><p>作业是在第一人称设计模板项目中实现以下功能：</p>
<p>一、物件规则：</p>
<ul>
<li>设计命中方块，获得积分X分</li>
<li>方块被子弹命中后缩放为Y倍，再次被命中后销毁</li>
</ul>
<p>二、游戏流程：</p>
<ol>
<li>游戏开始时随机N个方块成为“重要目标”，射击命中后获得双倍积分。</li>
<li>游戏开始后限时T秒，时间到后游戏结算，打印日志输出每个玩家获得的积分和所有玩家获得的总积分</li>
</ol>
<p>三、附加题</p>
<ol>
<li>利用UMG制作结算UI替代日志打印</li>
<li>支持多人联机</li>
</ol>
<p><strong>（目前还不太懂UE的C++的代码规范和继承调用结构，就先用蓝图做一做😭）</strong></p>
<h2 id="效果视频"><a href="#效果视频" class="headerlink" title="效果视频"></a>效果视频</h2><p><strong>如果您不想看细节那么可以直接看我的效果视频：</strong></p>
<iframe src="//player.bilibili.com/player.html?isOutside=true&aid=113565109459051&bvid=BV1cNzqYCETp&cid=27089309655&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe>

<h2 id="一、物件规则："><a href="#一、物件规则：" class="headerlink" title="一、物件规则："></a>一、物件规则：</h2><p>​	首先对于“设计命中方块，获得积分X分；方块被子弹命中后缩放为Y倍，再次被命中后销毁”我做以下操作：</p>
<ol>
<li>​	为了实现这个操作，那么我需要先在我的Character中设置一个变量：例如我是在BP_FirstPersonCharacter中进行设置，添加变量Score,类型为Integer。并且将其设置为Public,默认值设置为0。这表示我目前这个角色所得的所有积分。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202411291011934.png" alt="image-20241129101113865"></p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202411291013668.png" alt="image-20241129101310590"></p>
<ol start="2">
<li>​	其次我们需要对于我们要射击的方块针对性的进行一下小小的修改。我们可以先创建一个继承于Actor的蓝图IBox。对于该类我们，首先我们先改一下材质，来和地图中的其他的方块从外形上来进行分割。这个材质的外形如下面所示：</li>
</ol>
<p>​					<img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202411291024975.png" alt="image-20241129102444784"></p>
<ol start="3">
<li>​	然后给该蓝图设置：可以被命中，并且产生碰撞。并且设置以下的变量：</li>
</ol>
<ul>
<li>缩放倍数Y，float型。默认设置为0.5</li>
</ul>
<blockquote>
<p>0.5表示第一次被击中后该方块会进行缩放，变成原来的0.5倍</p>
</blockquote>
<ul>
<li>hitcount，Integer型，默认值设置为0</li>
</ul>
<blockquote>
<p>该变量可以进行记录我们的该方块的被击打次数。默认被击打次数为0</p>
</blockquote>
<ul>
<li>方块得分X，Integer型，默认值为10</li>
</ul>
<blockquote>
<p>表示我们如果命中该方块，那么命中该方块的角色的得分Score会进行增加X分，此时若要实现多人联机模式，那么就需要对于产生EventHit的“子弹”进行溯源找到对应的Charactor。</p>
</blockquote>
<ul>
<li>IsImportant，Boolean型，默认值为False，设置为Public。</li>
</ul>
<blockquote>
<p>表示该目标实例是否是重要目标，若击中重要目标那么就会产生双倍得分并且这一变量可以在外部调用和编辑，以便我们可以在游戏开始的时候对于地图中的重要目标进行初始化，来随机选取特定个方块设置为重要目标</p>
</blockquote>
<p>IBox中变量的全家福如下：</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202411291052816.png" alt="image-20241129105252722"></p>
<ol start="4">
<li>​	首先在IBox的蓝图中，我们先生成一个EventHit事件检查碰撞，并且检查碰撞的Other对象是否为子弹实例，如果是那么就找到对应的射击角色然后进入流程并且接入判断本实例是否是important实例的Branch：</li>
</ol>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202411291413133.png" alt="image-20241129141320002"></p>
<ol start="5">
<li>​	然后根据本目标是否是重要目标进行加分操作，如果是重要目标那么就对对应的Charactor的Score变量加上双倍的对应得分，如果不是那么就加上单倍得分。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202411291416810.png" alt="image-20241129141624694"></p>
<ol start="6">
<li>​	之后再对本实例中的hitcount变量进行加一操作并且每次加一结束后要进行判断，判断该物体的受打击次数并且转跳到对应的分支。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202411291419347.png" alt="image-20241129141911259"></p>
<ol start="7">
<li>​	最后根据被击中的次数来对箱子产生销毁或者缩放操作。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202411291420702.png" alt="image-20241129142027582"></p>
<ol start="8">
<li>​	同时我也对于BP_FirstPersonProjectile类进行了一些修改。关闭了子弹的“抛射物反弹”功能和“重力功能”。还有就是碰撞检测到后即可销毁等一些操作。</li>
</ol>
<p>至此物件规则这一部分就已经完成了。</p>
<h2 id="二、游戏流程"><a href="#二、游戏流程" class="headerlink" title="二、游戏流程"></a>二、游戏流程</h2><blockquote>
<ol>
<li>游戏开始时随机N个方块成为“重要目标”，射击命中后获得双倍积分。</li>
<li>游戏开始后限时T秒，时间到后游戏结算，打印日志输出每个玩家获得的积分和所有玩家获得的总积分</li>
</ol>
</blockquote>
<p>​	对于该目标我需要对于游戏的GameMode蓝图进行操作，并且在其中添加一些规则。</p>
<p>为了实现以上的功能我在BP_FirstPersonGameMode中设置了以下变量：</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202411291435655.png" alt="image-20241129143528584"></p>
<p>其中GameTimeLimit指定了游戏的限时规则。在蓝图中这样子显示</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202411291437539.png" alt="image-20241129143733448"></p>
<p>其中OnGameTimerTick函数我做出的设计如下：</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202411291438914.png" alt="image-20241129143847788"></p>
<p>其中的末尾函数OnGameEnd函数我的设计如下，就是简单的打印输入总积分。</p>
<blockquote>
<p>这里没有设置UI和跳出是因为我个人学校课业压力和科研压力和时间紧迫的原因，（更多是因为我自己菜😭）</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202411291441875.png" alt="image-20241129144158763"></p>
<p>之后在主逻辑蓝图中取出所有的实例并且对于其中的实例循环N次找出其中的N个随机的重要目标并进行相关操作：</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202411291452639.png" alt="image-20241129145226565"></p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202411291454280.png" alt="image-20241129145401201"></p>
<p>至此所有的主逻辑设计都完成了。</p>
<h2 id="三、附加：简单UI设计"><a href="#三、附加：简单UI设计" class="headerlink" title="三、附加：简单UI设计"></a>三、附加：简单UI设计</h2><p>设计结果如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202411291509578.png" alt="image-20241129150902463"></p>
<p>其中两个TextBlock函数分别绑定：Score（位于Charactor）、CurrentGameTime(位于GameMode)两个变量。</p>
<p>总结下来还是比较简陋的完成了作业。</p>
<p>演示图片：</p>
<p>以下为场景摆放</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202411291515872.png" alt="image-20241129151556625"></p>
<p>开始游戏后材质变成草皮的方块就是被系统选定的重要目标。</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202411291516354.png" alt="image-20241129151647094"></p>
<p>当第一次击中目标后方块会产生缩放效果</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202411291519881.png" alt="image-20241129151928706"></p>
<p>第二次击中后会销毁方块（这里没抓住timing就没截到图）建议还是查看录屏。</p>
]]></content>
      <categories>
        <category>UE5</category>
      </categories>
      <tags>
        <tag>UE5</tag>
      </tags>
  </entry>
  <entry>
    <title>go语言编写的文件服务器</title>
    <url>/2025/03/09/go%E8%AF%AD%E8%A8%80%E7%BC%96%E5%86%99%E7%9A%84%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
    <content><![CDATA[<h1 id="简易用户文件系统"><a href="#简易用户文件系统" class="headerlink" title="简易用户文件系统"></a>简易用户文件系统</h1><p>项目地址：<a href="https://github.com/jianingdai/filesysByGo">https://github.com/jianingdai/filesysByGo</a></p>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><ol>
<li><p>在 <code>08</code> 文件夹中使用以下命令来启动服务程序</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">go run ./cmd/filesys/main.go</span><br></pre></td></tr></table></figure></li>
<li><p><strong>！！！第一次运行时需要在 <code>08</code> 文件夹下依次运行以下两个命令：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">go run ./cmd/init_db/main.go</span><br><span class="line">go run ./cmd/gen/main.go</span><br></pre></td></tr></table></figure></li>
</ol>
<p>文件管理系统的默认开启端口为 8080 端口。</p>
<p>访问运行服务程序主机的 8080 端口就可以查看并且测试文件系统，不过前端界面只是测试界面，是一个很简陋的测试界面。</p>
<h2 id="功能概述"><a href="#功能概述" class="headerlink" title="功能概述"></a>功能概述</h2><ol>
<li>实现一个简易的用户文件系统。</li>
<li>每个用户拥有独立的文件树，节点类型包括文件和文件夹。</li>
<li>每个文件或文件夹都有唯一 ID，根目录文件夹 ID 为 0。</li>
<li>支持文件和文件夹的基本操作接口。</li>
<li>系统默认自带管理员账号 <code>admin</code>，仅管理员可创建其他用户。</li>
<li>同一文件夹下文件和文件夹均不可重名，若重名则自动重命名（规则参考 Windows）。</li>
<li>文件支持版本管理，版本号从 1 开始递增，当前版本号最大。</li>
<li><del>高级功能：客户端配合服务端使用 rsync 差分算法实现历史版本增量上传（后续版本实现）。</del></li>
<li>文件存储于工程根目录下的 <a href="week01/practice/go/08/frontend/main.js"><code>data</code></a> 目录，需考虑磁盘文件清理。</li>
<li>推荐使用 Postman 进行接口测试，支持简单前端页面展示更佳。</li>
</ol>
<h2 id="技术栈"><a href="#技术栈" class="headerlink" title="技术栈"></a>技术栈</h2><ul>
<li>Web 框架：<a href="https://github.com/gin-gonic/gin">Gin</a></li>
<li>ORM 框架：<a href="https://gorm.io/">GORM</a></li>
<li>数据库：SQLite</li>
<li>代码生成工具：<a href="https://gorm.io/gen/">GORM Gen</a></li>
</ul>
<h2 id="分层设计"><a href="#分层设计" class="headerlink" title="分层设计"></a>分层设计</h2><p>该项目采用分层设计，主要分为以下几层：</p>
<ul>
<li><strong>cmd</strong>: 包含可执行文件，例如：<ul>
<li><code>filesys</code>: 主程序入口，负责初始化数据库连接、启动 utils.StartSessionCleaner() 定时清理过期 session 的协程，以及初始化并启动 router。</li>
<li><code>init_db</code>: 初始化数据库，创建表结构并创建默认管理员用户。</li>
<li><code>gen</code>: 使用 GORM Gen 自动生成数据库访问代码。<ul>
<li><strong>注意</strong>: 首次运行项目时，需要先运行 <code>init_db</code> 初始化数据库，然后运行 <code>gen</code> 生成数据库访问代码。</li>
</ul>
</li>
</ul>
</li>
<li><strong>dao</strong>: 数据库访问层，包含自动生成的数据库操作代码。 使用 GORM Gen 根据数据库表结构自动生成，位于 dao 目录。<ul>
<li>该层主要通过 GORM 提供的 API 进行数据库操作，例如：<ul>
<li><code>Create</code>: 创建数据。</li>
<li><code>Find</code>: 查询数据。</li>
<li><code>Update</code>: 更新数据。</li>
<li><code>Delete</code>: 删除数据。</li>
</ul>
</li>
</ul>
</li>
<li><strong>models</strong>: 数据库模型定义，定义了数据库表的结构体。 位于 models_def 目录。<ul>
<li><p>例如，<code>User</code> 结构体定义了用户表的结构：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> User <span class="keyword">struct</span> &#123;</span><br><span class="line">    ID        <span class="type">int64</span>     <span class="string">`gorm:&quot;primaryKey;autoIncrement&quot;`</span></span><br><span class="line">    Username  <span class="type">string</span>    <span class="string">`gorm:&quot;type:varchar(255);not null;unique&quot;`</span></span><br><span class="line">    Password  <span class="type">string</span>    <span class="string">`gorm:&quot;type:varchar(255);not null&quot;`</span></span><br><span class="line">    CreatedAt time.Time</span><br><span class="line">    UpdatedAt time.Time</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><code>File</code> 结构体定义了文件表的结构：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> File <span class="keyword">struct</span> &#123;</span><br><span class="line">    ID        <span class="type">int64</span>     <span class="string">`gorm:&quot;primaryKey;autoIncrement&quot;`</span></span><br><span class="line">    UserID    <span class="type">int64</span>     <span class="string">`gorm:&quot;not null&quot;`</span></span><br><span class="line">    ParentID  <span class="type">int64</span>     <span class="string">`gorm:&quot;not null&quot;`</span></span><br><span class="line">    Name      <span class="type">string</span>    <span class="string">`gorm:&quot;type:varchar(255);not null&quot;`</span></span><br><span class="line">    Type      <span class="type">int</span>       <span class="string">`gorm:&quot;not null&quot;`</span> <span class="comment">// 0: 文件夹, 1: 文件</span></span><br><span class="line">    Size      <span class="type">int64</span>     <span class="string">`gorm:&quot;not null&quot;`</span></span><br><span class="line">    Hash      <span class="type">string</span>    <span class="string">`gorm:&quot;type:varchar(255)&quot;`</span></span><br><span class="line">    Version   <span class="type">int</span>       <span class="string">`gorm:&quot;not null;default:1&quot;`</span></span><br><span class="line">    CreatedAt time.Time</span><br><span class="line">    UpdatedAt time.Time</span><br><span class="line">    DeletedAt gorm.DeletedAt <span class="string">`gorm:&quot;index&quot;`</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><strong>endpoint</strong>: 接口处理层，负责接收 HTTP 请求、参数校验、调用 service 层处理业务逻辑，并将结果返回给客户端。<ul>
<li><p>该层使用了 Gin 框架提供的 API 进行路由注册和请求处理。</p>
</li>
<li><p>例如，<code>CreateUser</code> 函数处理创建用户请求：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">CreateUser</span><span class="params">(c *gin.Context)</span></span> &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="keyword">if</span> err := s.CreateUser(username, password); err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><strong>service</strong>: 业务逻辑层，负责实现具体的业务逻辑，例如：<ul>
<li>文件上传、下载、删除、复制、移动、重命名等。</li>
<li>用户登录、创建等。</li>
<li>该层主要调用 dao 层提供的 API 进行数据库操作，并进行必要的业务逻辑处理。</li>
</ul>
</li>
<li><strong>middleware</strong>: 中间件层，负责处理一些通用的逻辑，例如：<ul>
<li>身份验证：<code>AuthMiddleware</code> 验证用户身份，并将用户 ID 存储在上下文中。<ul>
<li>该中间件通过检查 Cookie 中的 <code>sid</code> 来验证用户身份。</li>
<li>如果用户已登录，则将用户 ID 存储在 Gin 的 Context 中，方便后续处理函数使用。</li>
</ul>
</li>
<li>权限验证：<code>FilePermissionMiddleware</code> 验证用户是否有权限访问指定文件。<ul>
<li>该中间件检查当前用户是否有权限访问指定文件，如果没有权限则返回 403 Forbidden 错误。</li>
</ul>
</li>
</ul>
</li>
<li><strong>frontend</strong>: 前端静态资源，包含 HTML、CSS 和 JavaScript 文件。<ul>
<li>前端代码位于 <code>frontend</code> 目录下。</li>
<li>前端使用 JavaScript 调用后端 API，实现文件管理功能。</li>
</ul>
</li>
<li><strong>utils</strong>: 包含一些实用工具函数，例如：<ul>
<li><code>utils.StartSessionCleaner()</code>：定时清理过期 session。<ul>
<li>该函数启动一个 Goroutine，定时清理过期的 session 数据。</li>
<li>Session 过期时间默认为 24 小时。</li>
</ul>
</li>
</ul>
</li>
<li><strong>router</strong>: 路由配置，负责将 HTTP 请求路由到相应的 endpoint 处理函数。<ul>
<li>路由配置位于 <code>router/router.go</code> 文件中。</li>
<li>该文件使用了 Gin 框架提供的 API 进行路由注册。</li>
</ul>
</li>
</ul>
<h2 id="接口说明"><a href="#接口说明" class="headerlink" title="接口说明"></a>接口说明</h2><h3 id="登录接口"><a href="#登录接口" class="headerlink" title="登录接口"></a>登录接口</h3><ul>
<li><code>POST /login</code><br>用户登录，返回 <code>sid</code>，后续接口需在 Cookie 中携带 <code>sid</code>。<ul>
<li>请求体参数：<code>username</code>、<code>password</code>。</li>
<li>成功登录后，服务器会生成一个 session ID，并将其存储在 Cookie 中。</li>
</ul>
</li>
</ul>
<h3 id="管理接口（仅管理员）"><a href="#管理接口（仅管理员）" class="headerlink" title="管理接口（仅管理员）"></a>管理接口（仅管理员）</h3><ul>
<li><code>POST /api/user/create</code><br>创建新用户。<ul>
<li>需要管理员权限。</li>
<li>请求体参数：<code>username</code>、<code>password</code>。</li>
<li>管理员用户可以通过该接口创建新的用户账号。</li>
</ul>
</li>
</ul>
<h3 id="文件接口"><a href="#文件接口" class="headerlink" title="文件接口"></a>文件接口</h3><ul>
<li><code>POST /api/file/&#123;file_id&#125;/new</code><br>新建文件夹，<code>file_id</code> 为父目录 ID，返回文件夹信息。<ul>
<li>请求体参数：<code>name</code> (文件夹名称)</li>
<li>在指定的父目录下创建一个新的文件夹。</li>
</ul>
</li>
<li><code>POST /api/file/&#123;file_id&#125;/upload</code><br>上传文件，<code>file_id</code> 为父目录 ID，文件二进制内容放在请求体，返回文件信息。<ul>
<li>请求体参数：文件二进制数据</li>
<li>在指定的父目录下上传一个新的文件。</li>
</ul>
</li>
<li><code>POST /api/file/&#123;file_id&#125;/update</code><br>更新文件，文件二进制内容放在请求体，返回文件信息。<ul>
<li>请求体参数：文件二进制数据</li>
<li>更新指定文件的内容。</li>
</ul>
</li>
<li><code>DELETE /api/file/&#123;file_id&#125;</code><br>删除文件或文件夹。<ul>
<li>删除指定的文件或文件夹。</li>
</ul>
</li>
<li><code>POST /api/file/&#123;file_id&#125;/copy</code><br>复制文件或文件夹。<ul>
<li>请求体参数：<code>dest_id</code> (目标父目录 ID)</li>
<li>将指定的文件或文件夹复制到目标父目录下。</li>
</ul>
</li>
<li><code>POST /api/file/&#123;file_id&#125;/move</code><br>移动文件或文件夹。<ul>
<li>请求体参数：<code>dest_id</code> (目标父目录 ID)</li>
<li>将指定的文件或文件夹移动到目标父目录下。</li>
</ul>
</li>
<li><code>POST /api/file/&#123;file_id&#125;/rename</code><br>重命名文件或文件夹。<ul>
<li>请求体参数：<code>new_name</code> (新的名称)</li>
<li>重命名指定的文件或文件夹。</li>
</ul>
</li>
<li><code>GET /api/file/&#123;file_id&#125;</code><br>获取文件或文件夹信息。<ul>
<li>返回文件或文件夹的详细信息，例如：ID、名称、类型、大小、创建时间等。</li>
</ul>
</li>
<li><code>GET /api/file/&#123;file_id&#125;/list</code><br>获取文件夹下的文件和文件夹列表。<ul>
<li>返回指定文件夹下的所有文件和文件夹的列表。</li>
</ul>
</li>
<li><code>GET /api/file/&#123;file_id&#125;/content</code><br>下载文件内容。<ul>
<li>返回指定文件的二进制内容。</li>
</ul>
</li>
<li><code>GET /api/file/&#123;file_id&#125;/version/&#123;ver_num&#125;/content</code><br>下载指定历史版本的文件内容。<ul>
<li>返回指定历史版本的文件二进制内容。</li>
</ul>
</li>
<li><code>GET /api/file/&#123;file_id&#125;/versions</code><br>获取文件的版本历史列表。<ul>
<li>返回指定文件的所有历史版本列表。</li>
</ul>
</li>
</ul>
<h2 id="数据库表结构"><a href="#数据库表结构" class="headerlink" title="数据库表结构"></a>数据库表结构</h2><ul>
<li><p><strong>users</strong>: 存储用户信息。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `users` (</span><br><span class="line">    `id` <span class="type">integer</span> <span class="keyword">PRIMARY</span> KEY AUTOINCREMENT,</span><br><span class="line">    `username` <span class="type">varchar</span>(<span class="number">255</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">UNIQUE</span>,</span><br><span class="line">    `password` <span class="type">varchar</span>(<span class="number">255</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    `created_at` datetime,</span><br><span class="line">    `updated_at` datetime</span><br><span class="line">);</span><br></pre></td></tr></table></figure></li>
<li><p><strong>files</strong>: 存储文件和文件夹信息。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `files` (</span><br><span class="line">    `id` <span class="type">integer</span> <span class="keyword">PRIMARY</span> KEY AUTOINCREMENT,</span><br><span class="line">    `user_id` <span class="type">integer</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    `parent_id` <span class="type">integer</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    `name` <span class="type">varchar</span>(<span class="number">255</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    `type` <span class="type">integer</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>, <span class="comment">-- 0: 文件夹, 1: 文件</span></span><br><span class="line">    `size` <span class="type">integer</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    `hash` <span class="type">varchar</span>(<span class="number">255</span>),</span><br><span class="line">    `version` <span class="type">integer</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="number">1</span>,</span><br><span class="line">    `created_at` datetime,</span><br><span class="line">    `updated_at` datetime,</span><br><span class="line">    `deleted_at` datetime</span><br><span class="line">);</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>后端开发</category>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>后端开发</tag>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title>UE5引擎源码版编译和Windows版本打包</title>
    <url>/2024/11/20/UE5%E5%BC%95%E6%93%8E%E6%BA%90%E7%A0%81%E7%89%88%E7%BC%96%E8%AF%91%E5%92%8CWindows%E7%89%88%E6%9C%AC%E6%89%93%E5%8C%85/</url>
    <content><![CDATA[<h1 id="读前须知"><a href="#读前须知" class="headerlink" title="读前须知"></a>读前须知</h1><hr>
<p>​	这里先贴出来<a href="https://dev.epicgames.com/documentation/zh-cn/unreal-engine/downloading-unreal-engine-source-code?application_version=5.4">Unreal Engine</a>的官方安装文档，本人就是跟着官方文档做的。这篇文章作为个人搭建记录和XX公司课程的作业提交。课程中网络相关问题均未提到，如果访问某些网站出现困难那么请自己寻求魔法。本文章目前只有windows版本的教程，mac和Linux的教程在我文章中提到的官方文档里均有提到。</p>
<h1 id="访问得到Github上的虚幻引擎的源代码"><a href="#访问得到Github上的虚幻引擎的源代码" class="headerlink" title="访问得到Github上的虚幻引擎的源代码"></a>访问得到Github上的虚幻引擎的源代码</h1><p>​	首先就是要有一个<a href="https://github.com/">GitHub</a>账号，没有的话要去注册一个。然后你可以看一下你的账号的profile中的Organizations中有没有epic这个标志，</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/imgimage-20241121004251563.png" alt="image-20241121004251563"></p>
<p>​	如果没有这个标志那么可以去<a href="https://www.unrealengine.com/zh-CN">Epic Games</a>登录然后在右上角可以点开自己的头像然后打开账户。要不然的话你点开UnrealEngine的源码仓库会出现访问404。</p>
<img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/imgimage-20241121002301539.png" alt="image-20241121002301539" style="zoom:;" />

<p>​	然后在左面点开应用与账户再点开右面的Github然后选择连接，按照操作进行关联就可以了。然后按照道理来说GitHub会发送邮件邀请你加入GitHub上的@EpicGames组织。你必须在7天内点击邮件内的 加入@EpicGames（Join @EpicGames） 按钮，才能完成GitHub与Epic Games账号的关联流程。但是我<strong>没有</strong>收到这份邮件，这个时候你不要急你等个几分钟然后去<a href="https://github.com/EpicGames">EpicGame的Github主页</a>这个时候你的页面上方应该会有一个消息提示其邀请你加入到Organizations中。如果没看见忘记点了也没事多刷新几次。</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/imgimage-20241121002700384.png" alt="image-20241121002700384"></p>
<p>​	等你加进组织之后再次访问就不会显示404了。然后你就可以进入到<a href="https://github.com/EpicGames/UnrealEngine">EpicGame的UnrealEngine仓库</a>中访问到Github上的虚幻引擎的源代码了。</p>
<h1 id="安装Visual-Studio-2022"><a href="#安装Visual-Studio-2022" class="headerlink" title="安装Visual Studio 2022"></a>安装Visual Studio 2022</h1><p>​	安装Visual Studio2022主要是用来编译和提供相关依赖。首先第一步访问<a href="https://visualstudio.microsoft.com/zh-hans/">VS</a>的官网然后点击下载Visual Studio安装程序，点开后选择我下图所展示的依赖点上：</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/imgimage-20241121125914604.png" alt="image-20241121125914604"></p>
<hr>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/imgimage-20241121125940979.png" alt="image-20241121125940979"></p>
<p>​	这一步官方也有详细文档指导，请点击这里：<a href="https://dev.epicgames.com/documentation/en-us/unreal-engine/setting-up-visual-studio-development-environment-for-cplusplus-projects-in-unreal-engine?application_version=5.4">UE5相关VS安装指导</a>，如果你在之后遇到相关问题记得回来检查版本是否匹配，截至这篇post提交时，官方版本匹配指导见下图：</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/imgimage-20241121130715320.png" alt="image-20241121130715320"></p>
<p>​	另外vs还可以安装自己喜欢的插件和主题，然后自己也可以进行各种设置外观等，这些我就不在这里赘述了，想要搞得自己可以慢慢调教。</p>
<h1 id="下载源码并且进行初始化"><a href="#下载源码并且进行初始化" class="headerlink" title="下载源码并且进行初始化"></a>下载源码并且进行初始化</h1><p>​	下载源码有多种方式可以直接对于指定的branch进行clone，也可以直接下载zip压缩包解压。</p>
<h2 id="clone方法"><a href="#clone方法" class="headerlink" title="clone方法"></a>clone方法</h2><p>​	首先要确保你的电脑安装了git，并且你的GitHub上已经绑定了你的本地git的ssh公钥，直接在你想要装Unreal Engine的目录中打开控制台然后输入以下命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> --depth 1 --branch 5.4 git@github.com:EpicGames/UnrealEngine.git</span><br></pre></td></tr></table></figure>

<h2 id="下载zip压缩包"><a href="#下载zip压缩包" class="headerlink" title="下载zip压缩包"></a>下载zip压缩包</h2><p>​	直接点击我的右面这个连接：<a href="https://github.com/EpicGames/UnrealEngine/releases">点我</a>，就可以进到UE的Releases的界面了，然后找到你想要下载的版本点开Assets点击Source code(zip)，msi后缀的是win上的安装包。然后就可以进行下载了，当下载完后直接解压就行。例如像我下图所示（推荐下载有发行版的releases一般来说会比较稳定）：</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/imgimage-20241121132853132.png" alt="image-20241121132853132"></p>
<p>​	当做到这里的时候你应该已经获得了源码了（差不多有2个GB）。</p>
<h2 id="下载二进制文件等和开始编译"><a href="#下载二进制文件等和开始编译" class="headerlink" title="下载二进制文件等和开始编译"></a>下载二进制文件等和开始编译</h2><ol>
<li><p>在资源管理器中打开你的源代码文件夹，并运行 <code>Setup.bat</code>。</p>
<p>这样将下载引擎的二进制内容和先决程序，并设置虚幻文件关联。 在Windows 8上，可能会显示SmartScreen警告。请依次单击 <strong>更多信息</strong> 和 <strong>Run anyway</strong> 以继续。</p>
<p>引擎二进制文件的完整下载包需要一些时间（差不多20个GB）才能完成下载。 后续检出只需要下载增量部分，速度将会大幅提高。</p>
</li>
<li><p>运行 <code>GenerateProjectFiles.bat</code> 来为引擎创建项目文件。这个过程应该不超过一分钟即可完成。</p>
</li>
<li><p>双击 <code>UE5.sln</code> 文件以将项目加载到Visual Studio中。将你的解决方案配置设置为 <strong>开发编辑器</strong>，将解决方案平台设置为 <strong>Win64</strong>，然后右键单击 <strong>UE</strong> 目标并选择 <strong>构建</strong>。大概需要10-40分钟完成编译，具体取决于系统规格。这里我的电脑编译了有1个多小时差不多，反正就是很耗时了，对电脑的CPU和内存有较大要求，CPU越强时间越短。</p>
</li>
<li><p>编译完成后，可以将启动项目设置为 <strong>UE5</strong> 并按 <strong>F5</strong> 进行调试，以便从Visual Studio加载编辑器。</p>
<p><strong>（请一定确保按照操作进行操作，否则会损失很多时间）</strong></p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/imgimage-20241121133941806.png" alt="image-20241121133941806"></p>
</li>
</ol>
<h1 id="创建UE5工程并且开始打包"><a href="#创建UE5工程并且开始打包" class="headerlink" title="创建UE5工程并且开始打包"></a>创建UE5工程并且开始打包</h1><p>​	当你第一次打开UE客户端的时候因为需要进行着色所以的话会很耗时，然后打开客户端进行创建项目，注意以下几个点，项目名称最好别用中文，最好用英文。</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/imgimage-20241121134504003.png" alt="image-20241121134504003"></p>
<h2 id="Windows平台打包"><a href="#Windows平台打包" class="headerlink" title="Windows平台打包"></a>Windows平台打包</h2><p>​	然后像下图一样就可以进行游戏的初次打包了：</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/imgimage-20241121134620003.png" alt="image-20241121134620003"></p>
<h2 id="Android平台打包"><a href="#Android平台打包" class="headerlink" title="Android平台打包"></a>Android平台打包</h2><p>如果想要进行Android平台的打包记得要下载Android Studio进行SDK和NDK的安装，还有就是JAVA的SDK也是需要的一定要注意一下自己有没有安装相关工具链，如果安装成功了应该是我这个样子的：</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/imgimage-20241121134916922.png" alt="image-20241121134916922"></p>
<p>​	如果没有安装的话可以看一下这个链接：<a href="https://dev.epicgames.com/documentation/zh-cn/unreal-engine/set-up-android-sdk-ndk-and-android-studio-using-turnkey-for-unreal-engine">点我</a>，这个官方文档有着详细的说明。</p>
<h1 id="打包成果展示"><a href="#打包成果展示" class="headerlink" title="打包成果展示"></a>打包成果展示</h1><p>经过一段时间的编译然后就生成了如下图所示的打包成果：</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/imgimage-20241121174901797.png" alt="image-20241121174901797"></p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/imgimage-20241121175156226.png" alt="image-20241121175156226"></p>
<p>实机运行效果如图所示：</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/imgimage-20241121175125192.png" alt="image-20241121175125192"></p>
<p>​	现在你成功制作了你自己的第一款游戏，具有逼真的物理模拟和极高的画质上限，现在你也可以叫自己为游戏制作工程师了~😍！</p>
<p>​	本教程到这里就结束了，如果还有什么问题可以在下面留言评论。</p>
]]></content>
      <categories>
        <category>UE5</category>
      </categories>
      <tags>
        <tag>UE5</tag>
      </tags>
  </entry>
  <entry>
    <title>网络监控命令行工具</title>
    <url>/2025/04/11/%E7%BD%91%E7%BB%9C%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<h1 id="网络监控命令行工具"><a href="#网络监控命令行工具" class="headerlink" title="网络监控命令行工具"></a>网络监控命令行工具</h1><p>项目地址：<a href="https://github.com/jianingdai/network-monitor">https://github.com/jianingdai/network-monitor</a></p>
<h2 id="项目简介"><a href="#项目简介" class="headerlink" title="项目简介"></a>项目简介</h2><p>这是一个基于 Go 语言开发的网络监控命令行工具，旨在帮助用户监控指定的目标（如网站或 IP 地址）的可用性和响应时间。通过该工具，用户可以方便地添加、删除监控目标，启动监控任务，并生成监控报告。</p>
<h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">network-monitor/</span><br><span class="line">├── cmd/         # 命令行定义</span><br><span class="line">├── core/        # 核心业务逻辑</span><br><span class="line">├── models/      # 数据模型</span><br><span class="line">├── utils/       # 通用工具</span><br><span class="line">├── config/      # 配置文件</span><br><span class="line">├── tests/       # 测试目录</span><br><span class="line">├── main.go      # 程序入口</span><br></pre></td></tr></table></figure>

<h2 id="核心功能"><a href="#核心功能" class="headerlink" title="核心功能"></a>核心功能</h2><ol>
<li><strong>添加监控目标</strong>：通过命令行添加需要监控的网站或 IP 地址。</li>
<li><strong>删除监控目标</strong>：移除不再需要监控的目标。</li>
<li><strong>列出监控目标</strong>：查看当前所有监控目标。</li>
<li><strong>启动监控任务</strong>：并发监控所有目标的可用性和响应时间。</li>
<li><strong>生成监控报告</strong>：统计监控结果，生成详细的报告。</li>
</ol>
<h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><ol>
<li><p>确保已安装 Go 开发环境。</p>
</li>
<li><p>克隆项目到本地：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> &lt;repository-url&gt;</span><br><span class="line"><span class="built_in">cd</span> network-monitor</span><br></pre></td></tr></table></figure>
</li>
<li><p>运行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">go run main.go add -n <span class="string">&quot;Google&quot;</span> -u <span class="string">&quot;https://google.com&quot;</span></span><br><span class="line">go run main.go start</span><br><span class="line">go run main.go report</span><br></pre></td></tr></table></figure>
</li>
<li><p>或者运行以下命令</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">go build .</span><br><span class="line">network-mintor.exe [<span class="built_in">command</span>]</span><br></pre></td></tr></table></figure>

<p>（先构建出监控工具然后就可以带上参数使用监控工具了）</p>
<h2 id="开发计划"><a href="#开发计划" class="headerlink" title="开发计划"></a>开发计划</h2><ul>
<li>支持多种检查方式（如 HTTP、Ping、DNS）。</li>
<li>集成报警功能（如邮件或短信通知）。</li>
<li>提供 Web 界面，展示监控数据。</li>
</ul>
]]></content>
      <categories>
        <category>后端开发</category>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>后端开发</tag>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title>生成式AI模型实现MNIST数据增强</title>
    <url>/2024/12/06/%E7%94%9F%E6%88%90%E5%BC%8FAI%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0MNIST%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/</url>
    <content><![CDATA[<h1 id="文档说明："><a href="#文档说明：" class="headerlink" title="文档说明："></a>文档说明：</h1><p>​	本文主要是作为我本身的结课的作业的一种提交形式。内容主要包括使用生成式AI模型实现MNIST数据增强。选用cGAN、VAE等生成式AI模型。在深度学习框架PyTorch上基于MNIST训练集优化所选生成式AI模型。基于定量性能指标：[分类准确率]对比无数据增强、有数据增强技术路线性能。并且对所选生成式AI模型分析其数据增强的效果差异并进行对比分析。</p>
<p>​	流程图如：</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202412061423492.png" alt="image-20241206142328369"></p>
<h1 id="VAE数据增强实现部分："><a href="#VAE数据增强实现部分：" class="headerlink" title="VAE数据增强实现部分："></a>VAE数据增强实现部分：</h1><p>​	VAE数据增强部分，我这里是分成了两个脚本文件来进行操作，其中一个文件是<code>train_vae.py</code>，这个文件主要是为了训练vae模型。然后还有一个文件，名字是<code>generate_vae.py</code>，该文件主要是利用训练好的vae模型对MNIST数据集进行数据增强，我这里是将MNIST的训练集中的每个样本图片都进行了重参数化（reparameterize）然后输入到Decoder中生成对应的数据样本，同时也是方便我获取生成样本的标签，这是因为VAE模型的Decoder是从潜在空间中生成的样本，本质上是无标签的，所以我要利用原样本的标签和其在潜在空间中的值，这会帮助我生成增强数据集。</p>
<h2 id="VAE训练代码train-vae-py："><a href="#VAE训练代码train-vae-py：" class="headerlink" title="VAE训练代码train_vae.py："></a>VAE训练代码<code>train_vae.py</code>：</h2><p>以下是我的<code>homeWork/train_vae.py</code>文件的说明：</p>
<p>该脚本在MNIST数据集上训练变分自编码器（VAE）。</p>
<h3 id="依赖项："><a href="#依赖项：" class="headerlink" title="依赖项："></a>依赖项：</h3><ul>
<li><code>torch</code></li>
<li><code>torch.nn</code></li>
<li><code>torch.optim</code></li>
<li><code>torch.utils.data</code></li>
<li><code>torchvision.datasets</code></li>
<li><code>torchvision.transforms</code></li>
</ul>
<h3 id="VAE模型："><a href="#VAE模型：" class="headerlink" title="VAE模型："></a>VAE模型：</h3><p>VAE模型由编码器和解码器组成。编码器将输入数据压缩到潜在空间表示，解码器从该表示中重构数据。</p>
<h4 id="编码器："><a href="#编码器：" class="headerlink" title="编码器："></a>编码器：</h4><ul>
<li><strong>输入</strong>：784维向量（展平的28x28图像）</li>
<li><strong>输出</strong>：两个20维向量（均值和对数方差）</li>
</ul>
<h4 id="解码器："><a href="#解码器：" class="headerlink" title="解码器："></a>解码器：</h4><ul>
<li><strong>输入</strong>：20维潜在向量</li>
<li><strong>输出</strong>：784维向量（重构的图像）</li>
</ul>
<h4 id="重参数化技巧："><a href="#重参数化技巧：" class="headerlink" title="重参数化技巧："></a>重参数化技巧：</h4><p>为了允许通过随机采样过程进行反向传播，使用重参数化技巧：$ z &#x3D; \mu + \epsilon \cdot \sigma\  $其中$\epsilon$是从标准正态分布中采样。</p>
<h3 id="损失函数："><a href="#损失函数：" class="headerlink" title="损失函数："></a>损失函数：</h3><p>VAE的损失函数由重构损失和KL散度组成：</p>
<ul>
<li><strong>重构损失</strong>：衡量重构图像与原始图像的匹配程度。</li>
<li><strong>KL散度</strong>：衡量潜在空间分布与标准正态分布的接近程度。</li>
</ul>
<h3 id="训练："><a href="#训练：" class="headerlink" title="训练："></a>训练：</h3><ol>
<li>加载MNIST数据集。</li>
<li>初始化VAE模型和优化器。</li>
<li>训练模型若干个epoch，更新模型参数以最小化损失函数。</li>
<li>将训练好的模型保存到文件。</li>
</ol>
<h3 id="代码："><a href="#代码：" class="headerlink" title="代码："></a>代码：</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义VAE模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VAE</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, latent_dim=<span class="number">20</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(VAE, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.encoder = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">784</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">2</span> * latent_dim)  <span class="comment"># 输出均值和对数方差</span></span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.decoder = nn.Sequential(</span><br><span class="line">            nn.Linear(latent_dim, <span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">784</span>),</span><br><span class="line">            nn.Sigmoid()  <span class="comment"># 输出值范围在[0, 1]</span></span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.latent_dim = latent_dim</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">self, x</span>):</span><br><span class="line">        h = <span class="variable language_">self</span>.encoder(x)</span><br><span class="line">        mu, log_var = h.chunk(<span class="number">2</span>, dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> mu, log_var</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reparameterize</span>(<span class="params">self, mu, log_var</span>):</span><br><span class="line">        std = torch.exp(<span class="number">0.5</span> * log_var)</span><br><span class="line">        eps = torch.randn_like(std)</span><br><span class="line">        <span class="keyword">return</span> mu + eps * std</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decode</span>(<span class="params">self, z</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.decoder(z)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        mu, log_var = <span class="variable language_">self</span>.encode(x.view(-<span class="number">1</span>, <span class="number">784</span>))</span><br><span class="line">        z = <span class="variable language_">self</span>.reparameterize(mu, log_var)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.decode(z), mu, log_var</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vae_loss</span>(<span class="params">recon_x, x, mu, log_var</span>):</span><br><span class="line">    recon_loss = nn.functional.binary_cross_entropy(recon_x, x.view(-<span class="number">1</span>, <span class="number">784</span>), reduction=<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line">    kl_divergence = -<span class="number">0.5</span> * torch.<span class="built_in">sum</span>(<span class="number">1</span> + log_var - mu.<span class="built_in">pow</span>(<span class="number">2</span>) - log_var.exp())</span><br><span class="line">    <span class="keyword">return</span> recon_loss + kl_divergence, recon_loss, kl_divergence</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 加载MNIST数据</span></span><br><span class="line">    transform = transforms.ToTensor()</span><br><span class="line">    mnist_train = datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, transform=transform, download=<span class="literal">True</span>)</span><br><span class="line">    mnist_loader = DataLoader(mnist_train, batch_size=<span class="number">128</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">4</span>, pin_memory=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化模型与优化器</span></span><br><span class="line">    latent_dim = <span class="number">20</span></span><br><span class="line">    vae = VAE(latent_dim=latent_dim).to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">    optimizer = optim.Adam(vae.parameters(), lr=<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        vae.load_state_dict(torch.load(<span class="string">&#x27;vae_gen_mnist.pth&#x27;</span>, weights_only=<span class="literal">True</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Model loaded successfully.&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> FileNotFoundError:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Model file not found. Initializing model with random weights.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练VAE模型</span></span><br><span class="line">    epochs = <span class="number">150</span></span><br><span class="line">    vae.train()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        train_loss = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> x, _ <span class="keyword">in</span> mnist_loader:</span><br><span class="line">            x = x.to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            recon_x, mu, log_var = vae(x)</span><br><span class="line">            loss, recon_loss, kl_divergence = vae_loss(recon_x, x, mu, log_var)</span><br><span class="line">            loss.backward()</span><br><span class="line">            train_loss += loss.item()</span><br><span class="line">            optimizer.step()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>, Total Loss: <span class="subst">&#123;train_loss / <span class="built_in">len</span>(mnist_loader.dataset):<span class="number">.4</span>f&#125;</span>, &quot;</span></span><br><span class="line">              <span class="string">f&quot;Reconstruction Loss: <span class="subst">&#123;recon_loss.item() / <span class="built_in">len</span>(mnist_loader.dataset):<span class="number">.4</span>f&#125;</span>, &quot;</span></span><br><span class="line">              <span class="string">f&quot;KL Divergence: <span class="subst">&#123;kl_divergence.item() / <span class="built_in">len</span>(mnist_loader.dataset):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存训练好的模型</span></span><br><span class="line">    torch.save(vae.state_dict(), <span class="string">&#x27;vae_gen_mnist.pth&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="VAE生成代码generate-vae-py"><a href="#VAE生成代码generate-vae-py" class="headerlink" title="VAE生成代码generate_vae.py:"></a>VAE生成代码<code>generate_vae.py</code>:</h2><p>该脚本使用预训练的变分自编码器（VAE）生成MNIST数据集的样本，并将生成的样本保存为<code>.ubyte</code>文件格式。</p>
<h3 id="依赖项：-1"><a href="#依赖项：-1" class="headerlink" title="依赖项："></a>依赖项：</h3><ul>
<li><code>torch</code></li>
<li><code>torch.nn</code></li>
<li><code>numpy</code></li>
<li><code>matplotlib.pyplot</code></li>
<li><code>torch.utils.data</code></li>
<li><code>torchvision.datasets</code></li>
<li><code>torchvision.transforms</code></li>
<li><code>torchvision.utils</code></li>
<li><code>struct</code></li>
</ul>
<h3 id="VAE模型：-1"><a href="#VAE模型：-1" class="headerlink" title="VAE模型："></a>VAE模型：</h3><p>VAE模型由编码器和解码器组成。编码器将输入数据压缩到潜在空间表示，解码器从该表示中重构数据。</p>
<h4 id="编码器：-1"><a href="#编码器：-1" class="headerlink" title="编码器："></a>编码器：</h4><ul>
<li><strong>输入</strong>：784维向量（展平的28x28图像）</li>
<li><strong>输出</strong>：两个20维向量（均值和对数方差）</li>
</ul>
<h4 id="解码器：-1"><a href="#解码器：-1" class="headerlink" title="解码器："></a>解码器：</h4><ul>
<li><strong>输入</strong>：20维潜在向量</li>
<li><strong>输出</strong>：784维向量（重构的图像）</li>
</ul>
<h4 id="重参数化技巧：-1"><a href="#重参数化技巧：-1" class="headerlink" title="重参数化技巧："></a>重参数化技巧：</h4><p>为了允许通过随机采样过程进行反向传播，使用重参数化技巧：$z &#x3D; \mu + \epsilon \cdot \sigma$ 其中$\epsilon$是从标准正态分布中采样。</p>
<h3 id="保存增强数据集方法："><a href="#保存增强数据集方法：" class="headerlink" title="保存增强数据集方法："></a>保存增强数据集方法：</h3><p><code>save_dataset(images_filepath, labels_filepath, dataset)</code>函数将生成的图像和标签保存为<code>.ubyte</code>文件格式。</p>
<ul>
<li><strong>参数</strong>：<ul>
<li><code>images_filepath</code>：图像文件路径</li>
<li><code>labels_filepath</code>：标签文件路径</li>
<li><code>dataset</code>：包含图像和标签的列表</li>
</ul>
</li>
</ul>
<h3 id="主要步骤："><a href="#主要步骤：" class="headerlink" title="主要步骤："></a>主要步骤：</h3><ol>
<li>定义VAE模型。</li>
<li>尝试加载预训练（如果有）的VAE模型权重。</li>
<li>加载MNIST数据集。</li>
<li>使用VAE生成样本。</li>
<li>将生成的样本保存为<code>VAE-Generated-images-idx3-ubyte</code>文件和<code>VAE-Generated-labels-idx1-ubyte</code>。</li>
</ol>
<h3 id="代码：-1"><a href="#代码：-1" class="headerlink" title="代码："></a>代码：</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> make_grid</span><br><span class="line"><span class="keyword">import</span> struct</span><br><span class="line"></span><br><span class="line"><span class="comment"># ======================== 定义VAE模型 ========================</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VAE</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, latent_dim=<span class="number">20</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(VAE, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.encoder = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">784</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">2</span> * latent_dim)  <span class="comment"># 输出均值和对数方差</span></span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.decoder = nn.Sequential(</span><br><span class="line">            nn.Linear(latent_dim, <span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">784</span>),</span><br><span class="line">            nn.Sigmoid()  <span class="comment"># 输出值范围在[0, 1]</span></span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.latent_dim = latent_dim</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">self, x</span>):</span><br><span class="line">        h = <span class="variable language_">self</span>.encoder(x)</span><br><span class="line">        mu, log_var = h.chunk(<span class="number">2</span>, dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> mu, log_var</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reparameterize</span>(<span class="params">self, mu, log_var</span>):</span><br><span class="line">        std = torch.exp(<span class="number">0.5</span> * log_var)</span><br><span class="line">        eps = torch.randn_like(std)</span><br><span class="line">        <span class="keyword">return</span> mu + eps * std</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decode</span>(<span class="params">self, z</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.decoder(z)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        mu, log_var = <span class="variable language_">self</span>.encode(x.view(-<span class="number">1</span>, <span class="number">784</span>))</span><br><span class="line">        z = <span class="variable language_">self</span>.reparameterize(mu, log_var)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.decode(z), mu, log_var</span><br><span class="line"></span><br><span class="line"><span class="comment"># ======================== 保存增强数据集方法 ========================</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_dataset</span>(<span class="params">images_filepath, labels_filepath, dataset</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;保存合并后的数据集到 .ubyte 文件&quot;&quot;&quot;</span></span><br><span class="line">    images = []</span><br><span class="line">    labels = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> image, label <span class="keyword">in</span> dataset:</span><br><span class="line">        images.append(image.numpy())</span><br><span class="line">        labels.append(label)</span><br><span class="line"></span><br><span class="line">    images = np.stack(images).astype(np.uint8)  <span class="comment"># 转为 [N, 28, 28] 的 uint8 数组</span></span><br><span class="line">    labels = np.array(labels, dtype=np.uint8)  <span class="comment"># 转为 uint8 的标签</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Labels before saving: <span class="subst">&#123;labels.shape&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Unique labels before saving: <span class="subst">&#123;np.unique(labels)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 写入图像文件</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(images_filepath, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(struct.pack(<span class="string">&#x27;&gt;IIII&#x27;</span>, <span class="number">2051</span>, <span class="built_in">len</span>(images), <span class="number">28</span>, <span class="number">28</span>))  <span class="comment"># Magic number 2051 for images</span></span><br><span class="line">        f.write(images.tobytes())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 写入标签文件</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(labels_filepath, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(struct.pack(<span class="string">&#x27;&gt;II&#x27;</span>, <span class="number">2049</span>, <span class="built_in">len</span>(labels)))  <span class="comment"># Magic number 2049 for labels</span></span><br><span class="line">        f.write(labels.tobytes())</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 加载训练好的模型</span></span><br><span class="line">    latent_dim = <span class="number">20</span></span><br><span class="line">    vae = VAE(latent_dim=latent_dim).to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">    vae.load_state_dict(torch.load(<span class="string">&#x27;vae_gen_mnist.pth&#x27;</span>, weights_only=<span class="literal">True</span>))</span><br><span class="line">    vae.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载MNIST数据集</span></span><br><span class="line">    transform = transforms.ToTensor()</span><br><span class="line">    mnist_train = datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, transform=transform, download=<span class="literal">True</span>)</span><br><span class="line">    mnist_loader = DataLoader(mnist_train, batch_size=<span class="number">128</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">4</span>, pin_memory=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ======================== 使用VAE生成样本 ========================</span></span><br><span class="line">    generated_samples = []</span><br><span class="line">    generated_labels = []</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> mnist_loader:</span><br><span class="line">            x = x.to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">            mu, log_var = vae.encode(x.view(-<span class="number">1</span>, <span class="number">784</span>))</span><br><span class="line">            z = vae.reparameterize(mu, log_var)</span><br><span class="line">            generated_images = vae.decode(z).cpu().view(-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>).numpy()  <span class="comment"># 转为 28x28 的 NumPy 数组</span></span><br><span class="line">            generated_samples.extend(generated_images)</span><br><span class="line">            generated_labels.extend(y.numpy())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将列表转换为单一 numpy 数组</span></span><br><span class="line">    generated_samples = np.array(generated_samples)  <span class="comment"># 转为 (N, 28, 28) 的 numpy 数组</span></span><br><span class="line">    generated_labels = np.array(generated_labels, dtype=np.uint8)  <span class="comment"># 转为 uint8 的标签数组</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 确保生成的样本数据在 [0, 255] 范围内</span></span><br><span class="line">    generated_samples = (generated_samples * <span class="number">255</span>).astype(np.uint8)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存生成的样本到 .ubyte 文件</span></span><br><span class="line">    generated_images_path = <span class="string">&#x27;./enhanced_mnist/VAE-Generated-images-idx3-ubyte&#x27;</span></span><br><span class="line">    generated_labels_path = <span class="string">&#x27;./enhanced_mnist/VAE-Generated-labels-idx1-ubyte&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将生成的样本和标签打包成数据集</span></span><br><span class="line">    generated_dataset = [(torch.tensor(image, dtype=torch.uint8), label) <span class="keyword">for</span> image, label <span class="keyword">in</span> <span class="built_in">zip</span>(generated_samples, generated_labels)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用 save_dataset 函数保存生成的数据集</span></span><br><span class="line">    save_dataset(generated_images_path, generated_labels_path, generated_dataset)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;生成的数据集已保存到文件：&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot; - 图像文件: <span class="subst">&#123;generated_images_path&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot; - 标签文件: <span class="subst">&#123;generated_labels_path&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="CGAN数据增强实现部分："><a href="#CGAN数据增强实现部分：" class="headerlink" title="CGAN数据增强实现部分："></a>CGAN数据增强实现部分：</h1><h2 id="CGAN训练代码train-gan-py"><a href="#CGAN训练代码train-gan-py" class="headerlink" title="CGAN训练代码train_gan.py:"></a>CGAN训练代码<code>train_gan.py</code>:</h2><h3 id="依赖项：-2"><a href="#依赖项：-2" class="headerlink" title="依赖项："></a>依赖项：</h3><p><code>torch</code><br><code>torchvision</code></p>
<h3 id="CGAN模型："><a href="#CGAN模型：" class="headerlink" title="CGAN模型："></a>CGAN模型：</h3><h4 id="生成器设计（Generator）"><a href="#生成器设计（Generator）" class="headerlink" title="生成器设计（Generator）:"></a>生成器设计（Generator）:</h4><p>​	生成器模型用于生成与真实图像相似的图像。其结构如下：  </p>
<h5 id="嵌入层："><a href="#嵌入层：" class="headerlink" title="嵌入层："></a>嵌入层：</h5><ul>
<li>label_emb：将类别标签嵌入到与噪声向量相同的维度中。</li>
<li>参数：num_classes（类别数），num_classes（嵌入向量维度）。</li>
</ul>
<h5 id="全连接层："><a href="#全连接层：" class="headerlink" title="全连接层："></a>全连接层：</h5><ul>
<li>fc：将噪声向量和嵌入标签连接起来，并通过全连接层进行处理。</li>
<li>全连接层参数：输入维度 input_size + num_classes，输出维度 num_feature。</li>
</ul>
<h5 id="卷积层："><a href="#卷积层：" class="headerlink" title="卷积层："></a>卷积层：</h5><ul>
<li>conv1_g：包含卷积层、批归一化层和ReLU激活函数。</li>
<li>卷积层参数：输入通道数 1，输出通道数 50，卷积核大小 3，填充 1。</li>
<li>conv2_g：包含卷积层、批归一化层和ReLU激活函数。</li>
<li>卷积层参数：输入通道数 50，输出通道数 25，卷积核大小 3，填充 1。</li>
<li>conv3_g：包含卷积层和Tanh激活函数。</li>
<li>卷积层参数：输入通道数 25，输出通道数 1，卷积核大小 2，步幅 2。</li>
</ul>
<h4 id="判别器设计（Discriminator）："><a href="#判别器设计（Discriminator）：" class="headerlink" title="判别器设计（Discriminator）："></a>判别器设计（Discriminator）：</h4><p>​	判别器模型用于区分真实图像和生成图像。其结构如下：  </p>
<h5 id="嵌入层：-1"><a href="#嵌入层：-1" class="headerlink" title="嵌入层："></a>嵌入层：</h5><ul>
<li>label_emb：将类别标签嵌入到与图像大小相同的向量中。</li>
<li>参数：num_classes（类别数），28 * 28（嵌入向量维度）。</li>
</ul>
<h5 id="卷积层：-1"><a href="#卷积层：-1" class="headerlink" title="卷积层："></a>卷积层：</h5><ul>
<li>conv1：包含卷积层、LeakyReLU激活函数和最大池化层。</li>
<li>卷积层参数：输入通道数 2，输出通道数 32，卷积核大小 5，填充 2。</li>
<li>conv2：包含卷积层、LeakyReLU激活函数和最大池化层。</li>
<li>卷积层参数：输入通道数 32，输出通道数 64，卷积核大小 5，填充 2。</li>
</ul>
<h5 id="全连接层：-1"><a href="#全连接层：-1" class="headerlink" title="全连接层："></a>全连接层：</h5><ul>
<li>fc：包含全连接层、LeakyReLU激活函数和Sigmoid激活函数。</li>
<li>全连接层参数：输入维度 64 * 7 * 7，输出维度 1024 和 1。</li>
</ul>
<h3 id="损失函数：-1"><a href="#损失函数：-1" class="headerlink" title="损失函数："></a>损失函数：</h3><p>GAN模型的损失函数是二元交叉熵损失函数（Binary Cross-Entropy Loss），定义如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">criterion = nn.BCELoss()</span><br></pre></td></tr></table></figure>

<p>在训练过程中，判别器和生成器的损失分别计算如下：</p>
<ul>
<li><p>判别器损失（<code>d_loss</code>）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">d_loss_real = criterion(real_out, real_label)</span><br><span class="line">d_loss_fake = criterion(fake_out, fake_label)</span><br><span class="line">d_loss = d_loss_real + d_loss_fake</span><br></pre></td></tr></table></figure>
</li>
<li><p>生成器损失（<code>g_loss</code>）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g_loss = criterion(output, real_label)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="训练：-1"><a href="#训练：-1" class="headerlink" title="训练："></a>训练：</h3><ol>
<li>加载MNIST数据集。</li>
<li>初始化GAN模型和优化器。</li>
<li>训练模型若干个epoch，更新模型参数以最小化损失函数。</li>
<li>将训练好的模型保存到文件。</li>
</ol>
<h3 id="代码：-2"><a href="#代码：-2" class="headerlink" title="代码："></a>代码：</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># # ======================== 创建保存图像的文件夹 ========================</span></span><br><span class="line"><span class="comment"># if not os.path.exists(&#x27;./GAN&#x27;):</span></span><br><span class="line"><span class="comment">#     os.mkdir(&#x27;./GAN&#x27;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ======================== 定义图像转换函数 ========================</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">to_img</span>(<span class="params">x</span>):</span><br><span class="line">    out = <span class="number">0.5</span> * (x + <span class="number">1</span>)</span><br><span class="line">    out = out.clamp(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    out = out.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ======================== 设置超参数 ========================</span></span><br><span class="line">batch_size = <span class="number">128</span> <span class="comment"># 批处理大小</span></span><br><span class="line">num_epoch = <span class="number">150</span>  <span class="comment"># 训练epoch</span></span><br><span class="line">z_dimension = <span class="number">100</span>  <span class="comment"># 噪声维度</span></span><br><span class="line">num_classes = <span class="number">10</span>  <span class="comment"># 类别数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ======================== 图像处理 ========================</span></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean=[<span class="number">0.5</span>], std=[<span class="number">0.5</span>])</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># ======================== 加载MNIST数据集 ========================</span></span><br><span class="line">mnist = datasets.MNIST(</span><br><span class="line">    root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, transform=transform, download=<span class="literal">True</span>)</span><br><span class="line">dataloader = torch.utils.data.DataLoader(</span><br><span class="line">    dataset=mnist, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ======================== 定义判别器模型 ========================</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.label_emb = nn.Embedding(num_classes, <span class="number">28</span> * <span class="number">28</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">2</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),  <span class="comment"># batch, 32, 28, 28</span></span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>)  <span class="comment"># batch, 32, 14, 14</span></span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),  <span class="comment"># batch, 64, 14, 14</span></span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>)  <span class="comment"># batch, 64, 7, 7</span></span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">64</span> * <span class="number">7</span> * <span class="number">7</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img, labels</span>):</span><br><span class="line">        label_embedding = <span class="variable language_">self</span>.label_emb(labels).view(labels.size(<span class="number">0</span>), <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">        x = torch.cat((img, label_embedding), <span class="number">1</span>)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv2(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        x = <span class="variable language_">self</span>.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ======================== 定义生成器模型 ========================</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, num_feature, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.label_emb = nn.Embedding(num_classes, num_classes)</span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(input_size + num_classes, num_feature)  <span class="comment"># batch, 3136=1x56x56</span></span><br><span class="line">        <span class="variable language_">self</span>.br = nn.Sequential(</span><br><span class="line">            nn.BatchNorm2d(<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.conv1_g = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">50</span>, <span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),  <span class="comment"># batch, 50, 56, 56</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">50</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.conv2_g = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">50</span>, <span class="number">25</span>, <span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),  <span class="comment"># batch, 25, 56, 56</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">25</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.conv3_g = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">25</span>, <span class="number">1</span>, <span class="number">2</span>, stride=<span class="number">2</span>),  <span class="comment"># batch, 1, 28, 28</span></span><br><span class="line">            nn.Tanh()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, noise, labels</span>):</span><br><span class="line">        label_embedding = <span class="variable language_">self</span>.label_emb(labels)</span><br><span class="line">        x = torch.cat((noise, label_embedding), -<span class="number">1</span>)</span><br><span class="line">        x = <span class="variable language_">self</span>.fc(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">1</span>, <span class="number">56</span>, <span class="number">56</span>)</span><br><span class="line">        x = <span class="variable language_">self</span>.br(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1_g(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv2_g(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv3_g(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># ======================== 初始化模型 ========================</span></span><br><span class="line">    discriminator = Discriminator(num_classes)</span><br><span class="line">    generator = Generator(z_dimension, <span class="number">3136</span>,num_classes)</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        discriminator = discriminator.cuda()</span><br><span class="line">        generator = generator.cuda()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ======================== 定义损失函数和优化器 ========================</span></span><br><span class="line">    <span class="comment"># 使用二元交叉熵损失函数</span></span><br><span class="line">    criterion = nn.BCELoss()</span><br><span class="line">    d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=<span class="number">0.0001</span>)</span><br><span class="line">    g_optimizer = torch.optim.Adam(generator.parameters(), lr=<span class="number">0.0001</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        generator.load_state_dict(torch.load(<span class="string">&#x27;./GAN_generator.pth&#x27;</span>, weights_only=<span class="literal">True</span>))</span><br><span class="line">        discriminator.load_state_dict(torch.load(<span class="string">&#x27;./GAN_discriminator.pth&#x27;</span>, weights_only=<span class="literal">True</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n--------Model restored--------\n&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> FileNotFoundError:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n--------Model not restored: File not found--------\n&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\n--------Model not restored: <span class="subst">&#123;e&#125;</span>--------\n&quot;</span>)</span><br><span class="line">    <span class="comment"># ======================== 训练模型 ========================</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">        <span class="keyword">for</span> i, (img, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">            num_img = img.size(<span class="number">0</span>)</span><br><span class="line">            real_img = Variable(img).cuda()</span><br><span class="line">            real_label = Variable(torch.ones(num_img)).cuda().unsqueeze(<span class="number">1</span>)</span><br><span class="line">            fake_label = Variable(torch.zeros(num_img)).cuda().unsqueeze(<span class="number">1</span>)</span><br><span class="line">            labels = Variable(labels).cuda()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Train Discriminator</span></span><br><span class="line">            real_out = discriminator(real_img, labels)</span><br><span class="line">            d_loss_real = criterion(real_out, real_label)</span><br><span class="line">            real_scores = real_out  <span class="comment"># Closer to 1 means better</span></span><br><span class="line"></span><br><span class="line">            z = Variable(torch.randn(num_img, z_dimension)).cuda()</span><br><span class="line">            fake_img = generator(z, labels)</span><br><span class="line">            fake_out = discriminator(fake_img, labels)</span><br><span class="line">            d_loss_fake = criterion(fake_out, fake_label)</span><br><span class="line">            fake_scores = fake_out  <span class="comment"># Closer to 0 means better</span></span><br><span class="line"></span><br><span class="line">            d_loss = d_loss_real + d_loss_fake</span><br><span class="line">            d_optimizer.zero_grad()</span><br><span class="line">            d_loss.backward()</span><br><span class="line">            d_optimizer.step()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Train Generator</span></span><br><span class="line">            z = Variable(torch.randn(num_img, z_dimension)).cuda()</span><br><span class="line">            fake_img = generator(z, labels)</span><br><span class="line">            output = discriminator(fake_img, labels)</span><br><span class="line">            g_loss = criterion(output, real_label)</span><br><span class="line"></span><br><span class="line">            g_optimizer.zero_grad()</span><br><span class="line">            g_loss.backward()</span><br><span class="line">            g_optimizer.step()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (i + <span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;Epoch [&#123;&#125;/&#123;&#125;], d_loss: &#123;:.6f&#125;, g_loss: &#123;:.6f&#125; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;D real: &#123;:.6f&#125;, D fake: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                    epoch, num_epoch, d_loss.item(), g_loss.item(),</span><br><span class="line">                    real_scores.data.mean(), fake_scores.data.mean()))</span><br><span class="line">    <span class="comment"># ======================== 保存模型 ========================</span></span><br><span class="line">    torch.save(generator.state_dict(), <span class="string">&#x27;./GAN_generator.pth&#x27;</span>)</span><br><span class="line">    torch.save(discriminator.state_dict(), <span class="string">&#x27;./GAN_discriminator.pth&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="CGAN生成代码generator-GAN-py："><a href="#CGAN生成代码generator-GAN-py：" class="headerlink" title="CGAN生成代码generator_GAN.py："></a>CGAN生成代码generator_GAN.py：</h2><h3 id="依赖项"><a href="#依赖项" class="headerlink" title="依赖项"></a>依赖项</h3><p>该项目需要以下依赖项：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch</span><br><span class="line">torchvision</span><br><span class="line">numpy</span><br></pre></td></tr></table></figure>

<h3 id="CGAN模型"><a href="#CGAN模型" class="headerlink" title="CGAN模型"></a>CGAN模型</h3><p>​	条件生成对抗网络 (CGAN) 是一种在训练过程中也利用标签的 GAN。生成器 - 给定标签和随机数组作为输入，该网络生成与对应相同标签的训练数据观察具有相同结构的数据。生成器用于生成与真实图像相似的图像，判别器用于区分真实图像和生成图像。在本文件中因为已经默认使用了MNIST数据集对模型进行过了训练，所以本文件中就没有用到辨别器（Discriminator），只用到了生成器。</p>
<p>生成器模型的结构如下：</p>
<ol>
<li><p><strong>嵌入层</strong>：</p>
<ul>
<li><code>label_emb</code>：将类别标签嵌入到与噪声向量相同的维度中。</li>
<li>参数：<code>num_classes</code>（类别数），<code>num_classes</code>（嵌入向量维度）。</li>
</ul>
</li>
<li><p><strong>全连接层</strong>：</p>
<ul>
<li><code>fc</code>：将噪声向量和嵌入标签连接起来，并通过全连接层进行处理。</li>
<li>参数：输入维度 <code>input_size + num_classes</code>，输出维度 <code>num_feature</code>。</li>
</ul>
</li>
<li><p><strong>卷积层</strong>：</p>
<ul>
<li><code>conv1_g</code>：包含卷积层、批归一化层和ReLU激活函数。<ul>
<li>参数：输入通道数 <code>1</code>，输出通道数 <code>50</code>，卷积核大小 <code>3</code>，填充 <code>1</code>。</li>
</ul>
</li>
<li><code>conv2_g</code>：包含卷积层、批归一化层和ReLU激活函数。<ul>
<li>参数：输入通道数 <code>50</code>，输出通道数 <code>25</code>，卷积核大小 <code>3</code>，填充 <code>1</code>。</li>
</ul>
</li>
<li><code>conv3_g</code>：包含卷积层和Tanh激活函数。<ul>
<li>参数：输入通道数 <code>25</code>，输出通道数 <code>1</code>，卷积核大小 <code>2</code>，步幅 <code>2</code>。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="保存数据集的方法"><a href="#保存数据集的方法" class="headerlink" title="保存数据集的方法"></a>保存数据集的方法</h3><p>该项目提供了一个方法来保存生成的数据集到 <code>.ubyte</code> 文件中：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">save_dataset</span>(<span class="params">images_filepath, labels_filepath, images, labels</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(images_filepath, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(struct.pack(<span class="string">&#x27;&gt;IIII&#x27;</span>, <span class="number">2051</span>, <span class="built_in">len</span>(images), <span class="number">28</span>, <span class="number">28</span>))  <span class="comment"># Magic number 2051 for images</span></span><br><span class="line">        f.write(images.tobytes())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(labels_filepath, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(struct.pack(<span class="string">&#x27;&gt;II&#x27;</span>, <span class="number">2049</span>, <span class="built_in">len</span>(labels)))  <span class="comment"># Magic number 2049 for labels</span></span><br><span class="line">        f.write(labels.tobytes())</span><br></pre></td></tr></table></figure>

<h3 id="主要步骤"><a href="#主要步骤" class="headerlink" title="主要步骤"></a>主要步骤</h3><ol>
<li><p><strong>导入必要的库</strong>：</p>
<ul>
<li>导入 <code>torch</code>、<code>torch.nn</code>、<code>numpy</code> 等库。</li>
</ul>
</li>
<li><p><strong>定义生成器模型</strong>：</p>
<ul>
<li><code>Generator</code> 类包含嵌入层、全连接层和卷积层，用于生成图像。</li>
</ul>
</li>
<li><p><strong>设置超参数</strong>：</p>
<ul>
<li>定义噪声维度、类别数、生成样本数量和输出目录。</li>
</ul>
</li>
<li><p><strong>加载生成器模型</strong>：</p>
<ul>
<li>初始化生成器模型，并加载预训练的模型权重。</li>
</ul>
</li>
<li><p><strong>生成数据集</strong>：</p>
<ul>
<li>使用生成器模型生成指定数量的样本和标签。</li>
</ul>
</li>
<li><p><strong>保存生成的样本到 <code>.ubyte</code> 文件</strong>：</p>
<ul>
<li>使用 <code>save_dataset</code> 方法将生成的样本和标签保存到文件<code>GAN-Generated-images-idx3-ubyte</code>和<code>GAN-Generated-labels-idx1-ubyte</code>中。</li>
</ul>
</li>
</ol>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> struct</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, num_feature, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.label_emb = nn.Embedding(num_classes, num_classes)</span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(input_size + num_classes, num_feature)  <span class="comment"># batch, 3136=1x56x56</span></span><br><span class="line">        <span class="variable language_">self</span>.br = nn.Sequential(</span><br><span class="line">            nn.BatchNorm2d(<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.conv1_g = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">50</span>, <span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),  <span class="comment"># batch, 50, 56, 56</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">50</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.conv2_g = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">50</span>, <span class="number">25</span>, <span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),  <span class="comment"># batch, 25, 56, 56</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">25</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.conv3_g = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">25</span>, <span class="number">1</span>, <span class="number">2</span>, stride=<span class="number">2</span>),  <span class="comment"># batch, 1, 28, 28</span></span><br><span class="line">            nn.Tanh()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, noise, labels</span>):</span><br><span class="line">        label_embedding = <span class="variable language_">self</span>.label_emb(labels)</span><br><span class="line">        x = torch.cat((noise, label_embedding), -<span class="number">1</span>)</span><br><span class="line">        x = <span class="variable language_">self</span>.fc(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">1</span>, <span class="number">56</span>, <span class="number">56</span>)</span><br><span class="line">        x = <span class="variable language_">self</span>.br(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1_g(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv2_g(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv3_g(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置超参数</span></span><br><span class="line">z_dimension = <span class="number">100</span>  <span class="comment"># 噪声维度</span></span><br><span class="line">num_classes = <span class="number">10</span>  <span class="comment"># 类别数</span></span><br><span class="line">num_samples = <span class="number">60000</span>  <span class="comment"># 生成样本数量</span></span><br><span class="line">output_dir = <span class="string">&#x27;./enhanced_mnist&#x27;</span>  <span class="comment"># 输出目录</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建输出目录</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_dir):</span><br><span class="line">    os.makedirs(output_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载生成器模型</span></span><br><span class="line">generator = Generator(z_dimension, <span class="number">3136</span>, num_classes)</span><br><span class="line">generator.load_state_dict(torch.load(<span class="string">&#x27;./GAN_generator.pth&#x27;</span>, weights_only=<span class="literal">True</span>))</span><br><span class="line">generator.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    generator = generator.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据集</span></span><br><span class="line">generated_samples = []</span><br><span class="line">generated_labels = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_samples):</span><br><span class="line">    z = Variable(torch.randn(<span class="number">1</span>, z_dimension)).cuda()</span><br><span class="line">    labels = Variable(torch.randint(<span class="number">0</span>, num_classes, (<span class="number">1</span>,))).cuda()</span><br><span class="line">    fake_img = generator(z, labels)</span><br><span class="line">    fake_img = fake_img.cpu().data.numpy().squeeze() * <span class="number">255</span>  <span class="comment"># 转为 numpy 数组并缩放到 [0, 255]</span></span><br><span class="line">    generated_samples.append(fake_img.astype(np.uint8))</span><br><span class="line">    generated_labels.append(labels.cpu().item())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将生成的样本和标签打包成数据集</span></span><br><span class="line">generated_samples = np.stack(generated_samples)</span><br><span class="line">generated_labels = np.array(generated_labels, dtype=np.uint8)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存生成的样本到 .ubyte 文件</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_dataset</span>(<span class="params">images_filepath, labels_filepath, images, labels</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(images_filepath, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(struct.pack(<span class="string">&#x27;&gt;IIII&#x27;</span>, <span class="number">2051</span>, <span class="built_in">len</span>(images), <span class="number">28</span>, <span class="number">28</span>))  <span class="comment"># Magic number 2051 for images</span></span><br><span class="line">        f.write(images.tobytes())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(labels_filepath, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(struct.pack(<span class="string">&#x27;&gt;II&#x27;</span>, <span class="number">2049</span>, <span class="built_in">len</span>(labels)))  <span class="comment"># Magic number 2049 for labels</span></span><br><span class="line">        f.write(labels.tobytes())</span><br><span class="line"></span><br><span class="line">generated_images_path = os.path.join(output_dir, <span class="string">&#x27;GAN-Generated-images-idx3-ubyte&#x27;</span>)</span><br><span class="line">generated_labels_path = os.path.join(output_dir, <span class="string">&#x27;GAN-Generated-labels-idx1-ubyte&#x27;</span>)</span><br><span class="line"></span><br><span class="line">save_dataset(generated_images_path, generated_labels_path, generated_samples, generated_labels)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;生成的数据集已保存到文件：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot; - 图像文件: <span class="subst">&#123;generated_images_path&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot; - 标签文件: <span class="subst">&#123;generated_labels_path&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="三种数据集可视化对比展示："><a href="#三种数据集可视化对比展示：" class="headerlink" title="三种数据集可视化对比展示："></a>三种数据集可视化对比展示：</h1><h2 id="原始MNIST数据集展示图："><a href="#原始MNIST数据集展示图：" class="headerlink" title="原始MNIST数据集展示图："></a>原始MNIST数据集展示图：</h2><p>​	<img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202412121937255.png" alt="plot_2024-12-12 00-02-25_0"></p>
<h2 id="VAE增强数据集展示图："><a href="#VAE增强数据集展示图：" class="headerlink" title="VAE增强数据集展示图："></a>VAE增强数据集展示图：</h2><p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202412122335686.png" alt="plot_2024-12-12 23-34-41_2"></p>
<h2 id="CGAN增强数据集展示图："><a href="#CGAN增强数据集展示图：" class="headerlink" title="CGAN增强数据集展示图："></a>CGAN增强数据集展示图：</h2><p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202412122336984.png" alt="plot_2024-12-12 23-34-41_1"></p>
<h1 id="分别用三种数据集训练分类模型："><a href="#分别用三种数据集训练分类模型：" class="headerlink" title="分别用三种数据集训练分类模型："></a>分别用三种数据集训练分类模型：</h1><h2 id="分类模型选择：LeNet5"><a href="#分类模型选择：LeNet5" class="headerlink" title="分类模型选择：LeNet5"></a>分类模型选择：LeNet5</h2><p>我的这里的深度学习的分类模型选择的是LeNet5模型，当然LeNet5模型本身可以对图像的横向纵向进行特征提取就可以达到99%的正确识别率具体为：</p>
<h3 id="LeNet5-模型"><a href="#LeNet5-模型" class="headerlink" title="LeNet5 模型"></a>LeNet5 模型</h3><p>LeNet5 是一个经典的卷积神经网络（CNN）模型，主要用于图像分类任务。其结构如下：</p>
<ol>
<li><p><strong>卷积层 1</strong> (<code>conv1</code>)：</p>
<ul>
<li>输入通道数：1</li>
<li>输出通道数：6</li>
<li>卷积核大小：5</li>
</ul>
</li>
<li><p><strong>卷积层 2</strong> (<code>conv2</code>)：</p>
<ul>
<li>输入通道数：6</li>
<li>输出通道数：16</li>
<li>卷积核大小：5</li>
</ul>
</li>
<li><p><strong>全连接层 1</strong> (<code>fc1</code>)：</p>
<ul>
<li>输入维度：16 * 4 * 4</li>
<li>输出维度：120</li>
</ul>
</li>
<li><p><strong>全连接层 2</strong> (<code>fc2</code>)：</p>
<ul>
<li>输入维度：120</li>
<li>输出维度：84</li>
</ul>
</li>
<li><p><strong>全连接层 3</strong> (<code>fc3</code>)：</p>
<ul>
<li>输入维度：84</li>
<li>输出维度：10</li>
</ul>
</li>
</ol>
<h3 id="前向传播过程"><a href="#前向传播过程" class="headerlink" title="前向传播过程"></a>前向传播过程</h3><ol>
<li>输入图像通过第一个卷积层 (<code>conv1</code>)，然后经过 ReLU 激活函数。</li>
<li>经过最大池化层 (<code>max_pool2d</code>)。</li>
<li>通过第二个卷积层 (<code>conv2</code>)，然后经过 ReLU 激活函数。</li>
<li>再次经过最大池化层 (<code>max_pool2d</code>)。</li>
<li>将特征图展平为一维向量。</li>
<li>通过第一个全连接层 (<code>fc1</code>)，然后经过 ReLU 激活函数。</li>
<li>通过第二个全连接层 (<code>fc2</code>)，然后经过 ReLU 激活函数。</li>
<li>通过第三个全连接层 (<code>fc3</code>)，输出分类结果。</li>
</ol>
<h3 id="类代码如下："><a href="#类代码如下：" class="headerlink" title="类代码如下："></a>类代码如下：</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet5</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(LeNet5, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">4</span> * <span class="number">4</span>, <span class="number">120</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = torch.relu(<span class="variable language_">self</span>.conv1(x))</span><br><span class="line">        x = torch.max_pool2d(x, <span class="number">2</span>)</span><br><span class="line">        x = torch.relu(<span class="variable language_">self</span>.conv2(x))</span><br><span class="line">        x = torch.max_pool2d(x, <span class="number">2</span>)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">16</span> * <span class="number">4</span> * <span class="number">4</span>)</span><br><span class="line">        x = torch.relu(<span class="variable language_">self</span>.fc1(x))</span><br><span class="line">        x = torch.relu(<span class="variable language_">self</span>.fc2(x))</span><br><span class="line">        x = <span class="variable language_">self</span>.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<h2 id="损失函数和优化器："><a href="#损失函数和优化器：" class="headerlink" title="损失函数和优化器："></a>损失函数和优化器：</h2><ol>
<li><p><strong>设置损失函数</strong>：</p>
<ul>
<li><code>criterion = nn.CrossEntropyLoss()</code>：使用交叉熵损失函数（Cross-Entropy Loss），这是一个常用的分类任务损失函数。</li>
</ul>
</li>
<li><p><strong>设置优化器</strong>：</p>
<ul>
<li><code>optimizer = optim.Adam(leNet.parameters(), lr=learning_rate)</code>：使用Adam优化器，并设置学习率。Adam优化器是一种自适应学习率优化算法，适用于大多数深度学习模型。</li>
</ul>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(leNet.parameters(), lr=learning_rate)</span><br></pre></td></tr></table></figure>

<h2 id="代码：-3"><a href="#代码：-3" class="headerlink" title="代码："></a>代码：</h2><p>三种训练LeNet5的代码都一样只有数据集加载处有些改动，写的时候为了方便调试拆成了3个单独的文件，其中一个利用GAN训练增强数据集<code>GAN_Train_LeNet_Combined.py</code>的代码如下，（另外两个VAE和Original都类似，仅仅只有加载数据集过程中有些小区别）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, ConcatDataset</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># ======================== 定义LeNet模型 ========================</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet5</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(LeNet5, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">4</span> * <span class="number">4</span>, <span class="number">120</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = torch.relu(<span class="variable language_">self</span>.conv1(x))</span><br><span class="line">        x = torch.max_pool2d(x, <span class="number">2</span>)</span><br><span class="line">        x = torch.relu(<span class="variable language_">self</span>.conv2(x))</span><br><span class="line">        x = torch.max_pool2d(x, <span class="number">2</span>)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">16</span> * <span class="number">4</span> * <span class="number">4</span>)</span><br><span class="line">        x = torch.relu(<span class="variable language_">self</span>.fc1(x))</span><br><span class="line">        x = torch.relu(<span class="variable language_">self</span>.fc2(x))</span><br><span class="line">        x = <span class="variable language_">self</span>.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># ======================== 加载增强的数据集 ========================</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_enhanced_dataset</span>(<span class="params">images_path, labels_path</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(images_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        images = np.frombuffer(f.read(), dtype=np.uint8, offset=<span class="number">16</span>).reshape(-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(labels_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        labels = np.frombuffer(f.read(), dtype=np.uint8, offset=<span class="number">8</span>)</span><br><span class="line">    <span class="keyword">return</span> [(torch.tensor(image, dtype=torch.float32).unsqueeze(<span class="number">0</span>), label) <span class="keyword">for</span> image, label <span class="keyword">in</span> <span class="built_in">zip</span>(images, labels)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># ======================== 设置超参数 ========================</span></span><br><span class="line">    batch_size = <span class="number">64</span></span><br><span class="line">    learning_rate = <span class="number">0.001</span></span><br><span class="line">    num_epochs = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># ======================== 数据预处理 ========================</span></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ======================== 加载MNIST数据集 ========================</span></span><br><span class="line">    train_dataset = datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, transform=transform, download=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># test_dataset = datasets.MNIST(root=&#x27;./data&#x27;, train=False, transform=transform, download=True)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># ======================== 加载增强的数据集 ========================</span></span><br><span class="line">    enhanced_images_path = <span class="string">&#x27;./enhanced_mnist/GAN-Generated-images-idx3-ubyte&#x27;</span></span><br><span class="line">    enhanced_labels_path = <span class="string">&#x27;./enhanced_mnist/GAN-Generated-labels-idx1-ubyte&#x27;</span></span><br><span class="line">    enhanced_dataset = load_enhanced_dataset(enhanced_images_path, enhanced_labels_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ======================== 合并数据集 ========================</span></span><br><span class="line">    combined_train_dataset = ConcatDataset([train_dataset, enhanced_dataset])</span><br><span class="line">    train_loader = DataLoader(combined_train_dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># ======================== 初始化模型、损失函数和优化器 ========================</span></span><br><span class="line">    leNet = LeNet5().to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = optim.Adam(leNet.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        leNet.load_state_dict(torch.load(<span class="string">&#x27;GAN_leNet_mnist.pth&#x27;</span>, weights_only=<span class="literal">True</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Model loaded successfully.&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> FileNotFoundError:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Model file not found. Initializing model with random weights.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ======================== 训练模型 ========================</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        leNet.train()</span><br><span class="line">        running_loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> images, labels <span class="keyword">in</span> train_loader:</span><br><span class="line">            images, labels = images.to(<span class="string">&#x27;cuda&#x27;</span>), labels.to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            outputs = leNet(images)</span><br><span class="line">            loss = criterion(outputs, labels)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch [<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>], Loss: <span class="subst">&#123;running_loss/<span class="built_in">len</span>(train_loader):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ======================== 保存模型 ========================</span></span><br><span class="line">    torch.save(leNet.state_dict(), <span class="string">&#x27;GAN_leNet_mnist.pth&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="效果对比"><a href="#效果对比" class="headerlink" title="效果对比"></a>效果对比</h1><p>这里基于MNIST测试集对比三种训练集得到的模型做分类准确率评估评估效果如下：</p>
<p><img src="https://raw.githubusercontent.com/jianingdai/Blog_img/main/img202412122341083.png" alt="plot_2024-12-12 23-34-41_3"></p>
<p>三种数据集分别训练LeNet5模型进行分类的成功率如下：</p>
<p>原始数据集：98.98%</p>
<p>利用VAE增强的数据集：98.80%</p>
<p>利用GAN增强的数据集：98.37%</p>
<h1 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h1><p>​	利用增强数据集训练的 LeNet 模型，分类效果略微下降了一些，但整体分类成功率仍能保持在 <strong>98%</strong> 以上。这可能是因为：</p>
<ol>
<li>VAE 和 CGAN 是基于训练集中的数据进行样本生成的，其生成的样本往往会使整个样本集的数据特征更加集中于某些特定方面。当生成的数据过于充分时，这种特性在训练 LeNet-5 时可能进一步削弱其泛化能力，从而导致<strong>过拟合</strong>，在测试集上表现为分类能力下降和性能减退。这一问题在 LeNet-5 这样的复杂多层卷积网络中尤为显著。</li>
<li>我认为，部分过拟合现象可能也与数据集本身过于简单有关。以 MNIST 数据集为例，其本身较为简单，而且训练集已经包含了 60,000 条数据，数量相当充足。在数据增强后，训练集的样本数量更是达到了 120,000 条。假设这些增强数据均为有效样本，那么对于像 LeNet-5 这样专注于分类任务的卷积神经网络来说，更容易出现<strong>过拟合</strong>现象。</li>
<li>CGAN 的工作模式可能会加重<strong>过拟合</strong>现象。这是因为 GAN 模式中的 Discriminator 是基于训练集对 Generator 生成的数据进行辨别的，而这种<strong>对抗性</strong>机制会导致 Discriminator 和 Generator 在训练集上表现得过于“精准”，从而更容易出现过拟合问题。</li>
</ol>
]]></content>
      <categories>
        <category>AI</category>
        <category>GenAI</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>VAE</tag>
        <tag>LeNet</tag>
        <tag>GenAI</tag>
        <tag>CGAN</tag>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title>高并发缓存系统</title>
    <url>/2025/07/15/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%BC%93%E5%AD%98%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h2 id="项目地址"><a href="#项目地址" class="headerlink" title="项目地址"></a>项目地址</h2><p>github地址： <a href="https://github.com/jianingdai/my_cache">https://github.com/jianingdai/my_cache</a></p>
<h2 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h2><p>在项目目录使用以下命令可以进行测试运行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">go run test.go</span><br></pre></td></tr></table></figure>



<p>项目实现了基础功能，以后可以进一步开发定制化功能</p>
<p><strong>目前只开发基础功能和接口可供其他相关项目使用相关接口或者完善现在还处于一个demo状态，待未来可以慢慢完善扩增。</strong></p>
<h2 id="项目描述"><a href="#项目描述" class="headerlink" title="项目描述"></a>项目描述</h2><p>实现一个高性能的内存缓存系统，支持多种数据结构、过期策略、持久化等功能。</p>
<p><strong><del>仿redis</del></strong></p>
<h2 id="功能要求"><a href="#功能要求" class="headerlink" title="功能要求"></a>功能要求</h2><ol>
<li><strong>数据结构</strong>：支持字符串、列表、哈希表、集合</li>
<li><strong>过期策略</strong>：TTL、LRU、LFU等多种过期策略</li>
<li><strong>持久化</strong>：支持AOF和RDB持久化</li>
<li><strong>主从复制</strong>：支持主从同步</li>
<li><strong>事务支持</strong>：支持原子性操作</li>
<li><strong>集群模式</strong>：支持数据分片和故障转移</li>
<li><strong>监控统计</strong>：提供详细的性能指标</li>
</ol>
]]></content>
      <categories>
        <category>后端开发</category>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>后端开发</tag>
        <tag>Golang</tag>
      </tags>
  </entry>
</search>
